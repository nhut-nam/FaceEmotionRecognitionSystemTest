[2025-09-27 17:42:01,127: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:42:01,128: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:42:53,883: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:42:53,894: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:49:04,580: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:49:04,582: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:51:25,287: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:51:25,289: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:51:35,495: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:51:35,497: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:51:35,499: INFO: common]: Directory created at: artifacts
[2025-09-27 17:52:17,625: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:52:17,628: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:52:17,630: INFO: common]: Directory created at: artifacts
[2025-09-27 17:53:53,298: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:53:53,301: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:53:53,302: INFO: common]: Directory created at: artifacts
[2025-09-27 17:55:31,643: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:55:31,645: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:55:31,646: INFO: common]: Directory created at: artifacts
[2025-09-27 17:57:22,258: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:57:22,260: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:57:22,261: INFO: common]: Directory created at: artifacts
[2025-09-27 17:58:13,194: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:58:13,196: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:58:13,197: INFO: common]: Directory created at: artifacts
[2025-09-27 17:58:45,292: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 17:58:45,295: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 17:58:45,297: INFO: common]: Directory created at: artifacts
[2025-09-27 17:58:45,298: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-27 18:02:10,953: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 18:02:10,955: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 18:02:10,956: INFO: common]: Directory created at: artifacts
[2025-09-27 18:02:10,958: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-27 18:05:16,751: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 18:05:16,753: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 18:05:16,754: INFO: common]: Directory created at: artifacts
[2025-09-27 18:05:16,754: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-27 18:05:20,454: INFO: 717126125]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-27 18:05:20,455: INFO: 717126125]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-27 21:28:55,793: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:28:55,805: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:28:55,806: INFO: common]: Directory created at: artifacts
[2025-09-27 21:29:16,734: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:29:16,737: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:29:16,738: INFO: common]: Directory created at: artifacts
[2025-09-27 21:34:10,457: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:34:10,459: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:34:10,460: INFO: common]: Directory created at: artifacts
[2025-09-27 21:37:07,223: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:37:07,226: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:37:07,227: INFO: common]: Directory created at: artifacts
[2025-09-27 21:37:07,228: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-27 21:37:42,116: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:37:42,118: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:37:42,120: INFO: common]: Directory created at: artifacts
[2025-09-27 21:37:42,120: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-27 21:38:19,655: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:38:19,658: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:38:19,659: INFO: common]: Directory created at: artifacts
[2025-09-27 21:38:19,660: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-27 21:38:33,411: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:38:33,414: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:38:33,415: INFO: common]: Directory created at: artifacts
[2025-09-27 21:38:33,415: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-27 21:38:33,767: INFO: 1567097251]: Model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=7, bias=True)
) - Parameters: 21288263
[2025-09-27 21:48:55,455: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-27 21:48:55,456: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:48:55,458: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:48:55,458: INFO: common]: Directory created at: artifacts
[2025-09-27 21:48:55,458: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-27 21:49:02,381: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-27 21:49:02,382: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-27 21:49:02,382: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-27 21:49:02,382: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-27 21:49:02,383: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:49:02,385: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:49:02,385: INFO: common]: Directory created at: artifacts
[2025-09-27 21:49:02,386: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-27 21:49:02,386: ERROR: main]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-27 21:49:02,386: ERROR: main]: name 'os' is not defined
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 20, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 13, in main
    prepare_base_model_config = config.get_prepare_base_model_config()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\config\configuration.py", line 36, in get_prepare_base_model_config
    base_model_path=Path(os.path.join(config.base_model_path)),
NameError: name 'os' is not defined
[2025-09-27 21:49:51,543: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-27 21:49:51,544: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:49:51,546: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:49:51,547: INFO: common]: Directory created at: artifacts
[2025-09-27 21:49:51,547: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-27 21:49:57,160: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-27 21:49:57,161: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-27 21:49:57,161: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-27 21:49:57,162: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-27 21:49:57,167: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-27 21:49:57,169: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-27 21:49:57,169: INFO: common]: Directory created at: artifacts
[2025-09-27 21:49:57,169: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-27 21:49:57,436: INFO: prepare_base_model]: Model: ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=7, bias=True)
) - Parameters: 21288263
[2025-09-27 21:49:57,507: INFO: main]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-28 09:43:34,819: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:43:34,831: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:43:34,833: INFO: common]: Directory created at: artifacts
[2025-09-28 09:43:34,834: ERROR: 4016484038]: "'ConfigBox' object has no attribute 'trained_model'"
Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'trained_model'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'trained_model'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'trained_model'. Did you mean: 'trained_model_path'?

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\config_box.py", line 29, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'trained_model'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'trained_model'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'trained_model'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'trained_model'. Did you mean: 'trained_model_path'?

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\4016484038.py", line 3, in <module>
    training_config = config.get_training_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\2991876576.py", line 14, in get_training_config
    trained_model_path = os.path.join(training_config.trained_model)
  File "box\\config_box.py", line 31, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'trained_model'". Did you mean: 'trained_model_path'?
[2025-09-28 09:44:02,940: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:44:02,942: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:44:02,943: INFO: common]: Directory created at: artifacts
[2025-09-28 09:44:02,943: ERROR: 4016484038]: "'ConfigBox' object has no attribute 'trained_model'"
Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'trained_model'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'trained_model'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'trained_model'. Did you mean: 'trained_model_path'?

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\config_box.py", line 29, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'trained_model'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'trained_model'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'trained_model'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'trained_model'. Did you mean: 'trained_model_path'?

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\4016484038.py", line 3, in <module>
    training_config = config.get_training_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\2991876576.py", line 14, in get_training_config
    trained_model_path = os.path.join(training_config.trained_model)
  File "box\\config_box.py", line 31, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'trained_model'". Did you mean: 'trained_model_path'?
[2025-09-28 09:44:12,855: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:44:12,857: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:44:12,858: INFO: common]: Directory created at: artifacts
[2025-09-28 09:44:12,858: ERROR: 4016484038]: "'ConfigBox' object has no attribute 'updated_base_model'"
Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'updated_base_model'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'updated_base_model'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'updated_base_model'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\config_box.py", line 29, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'updated_base_model'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'updated_base_model'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'updated_base_model'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'updated_base_model'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\4016484038.py", line 3, in <module>
    training_config = config.get_training_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\362330020.py", line 15, in get_training_config
    updated_base_model_path = os.path.join(training_config.updated_base_model)
  File "box\\config_box.py", line 31, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'updated_base_model'"
[2025-09-28 09:44:38,688: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:44:38,691: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:44:38,692: INFO: common]: Directory created at: artifacts
[2025-09-28 09:44:38,692: ERROR: 4016484038]: "'ConfigBox' object has no attribute 'updated_base_model_path'"
Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'updated_base_model_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'updated_base_model_path'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'updated_base_model_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\config_box.py", line 29, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'updated_base_model_path'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'updated_base_model_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'updated_base_model_path'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'updated_base_model_path'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\4016484038.py", line 3, in <module>
    training_config = config.get_training_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\1590291379.py", line 15, in get_training_config
    updated_base_model_path = os.path.join(training_config.updated_base_model_path)
  File "box\\config_box.py", line 31, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'updated_base_model_path'"
[2025-09-28 09:45:59,786: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:45:59,788: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:45:59,789: INFO: common]: Directory created at: artifacts
[2025-09-28 09:45:59,789: ERROR: 4016484038]: 'ConfigurationManager' object has no attribute 'training_config'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\4016484038.py", line 3, in <module>
    training_config = config.get_training_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\1020190894.py", line 17, in get_training_config
    dataset_path = os.path.join(self.training_config.dataset_path)
AttributeError: 'ConfigurationManager' object has no attribute 'training_config'. Did you mean: 'get_training_config'?
[2025-09-28 09:47:28,733: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:47:28,735: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:47:28,736: INFO: common]: Directory created at: artifacts
[2025-09-28 09:47:28,736: ERROR: 4016484038]: 'ConfigurationManager' object has no attribute 'training_config'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\4016484038.py", line 3, in <module>
    training_config = config.get_training_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\1020190894.py", line 17, in get_training_config
    dataset_path = os.path.join(self.training_config.dataset_path)
AttributeError: 'ConfigurationManager' object has no attribute 'training_config'. Did you mean: 'get_training_config'?
[2025-09-28 09:48:43,387: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:48:43,388: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:48:43,389: INFO: common]: Directory created at: artifacts
[2025-09-28 09:48:43,390: ERROR: 4016484038]: Argument path_to_directories of type <class 'pathlib.WindowsPath'> to <function create_directories at 0x0000013EDAED9CF0> does not match annotation type <class 'list'>
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\4016484038.py", line 3, in <module>
    training_config = config.get_training_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\1109426850.py", line 19, in get_training_config
    create_directories(Path(training_config.root_dir))
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\ensure\main.py", line 833, in __call__
    raise EnsureError(msg.format(arg=arg, f=self.f, t=templ, valt=type(value)))
ensure.main.EnsureError: Argument path_to_directories of type <class 'pathlib.WindowsPath'> to <function create_directories at 0x0000013EDAED9CF0> does not match annotation type <class 'list'>
[2025-09-28 09:49:35,237: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:49:35,239: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:49:35,240: INFO: common]: Directory created at: artifacts
[2025-09-28 09:49:35,241: INFO: common]: Directory created at: artifacts\training
[2025-09-28 09:49:35,241: ERROR: 4016484038]: "'ConfigBox' object has no attribute 'num_classes'"
Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'NUM_CLASSES'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'NUM_CLASSES'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'NUM_CLASSES'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\config_box.py", line 29, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'NUM_CLASSES'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 594, in box.box.Box.__getitem__
KeyError: 'num_classes'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "box\\box.py", line 633, in box.box.Box.__getattr__
  File "box\\box.py", line 621, in box.box.Box.__getitem__
box.exceptions.BoxKeyError: "'num_classes'"

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "box\\box.py", line 635, in box.box.Box.__getattr__
AttributeError: 'ConfigBox' object has no attribute 'num_classes'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\4016484038.py", line 3, in <module>
    training_config = config.get_training_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\905312459.py", line 26, in get_training_config
    params_num_classes = params.NUM_CLASSES
  File "box\\config_box.py", line 31, in box.config_box.ConfigBox.__getattr__
  File "box\\box.py", line 649, in box.box.Box.__getattr__
box.exceptions.BoxKeyError: "'ConfigBox' object has no attribute 'num_classes'"
[2025-09-28 09:50:42,444: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:50:42,455: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:50:42,456: INFO: common]: Directory created at: artifacts
[2025-09-28 09:50:42,457: INFO: common]: Directory created at: artifacts\training
[2025-09-28 09:50:42,458: ERROR: 4016484038]: TrainingConfig.__init__() got an unexpected keyword argument 'dataset_path'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\4016484038.py", line 3, in <module>
    training_config = config.get_training_config()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9468\905312459.py", line 29, in get_training_config
    training_config = TrainingConfig(
TypeError: TrainingConfig.__init__() got an unexpected keyword argument 'dataset_path'
[2025-09-28 09:53:11,226: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:53:11,229: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:53:11,231: INFO: common]: Directory created at: artifacts
[2025-09-28 09:53:11,232: INFO: common]: Directory created at: artifacts\training
[2025-09-28 09:53:11,313: ERROR: 4016484038]: [Errno 2] No such file or directory: 'artifacts\\data'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_19772\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_19772\1488135359.py", line 18, in train
    self.extract_dataset()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_19772\1488135359.py", line 9, in extract_dataset
    with ZipFile(self.config.dataset_path, 'r') as zip_ref:
  File "c:\Users\namnh\miniconda3\envs\FER\lib\zipfile.py", line 1254, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data'
[2025-09-28 09:55:27,815: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:55:27,817: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:55:27,818: INFO: common]: Directory created at: artifacts
[2025-09-28 09:55:27,819: INFO: common]: Directory created at: artifacts\training
[2025-09-28 09:55:27,896: ERROR: 4016484038]: [Errno 13] Permission denied: 'artifacts\\data'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_19772\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_19772\143940723.py", line 19, in train
    self.extract_dataset()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_19772\143940723.py", line 10, in extract_dataset
    with ZipFile(self.config.dataset_path, 'r') as zip_ref:
  File "c:\Users\namnh\miniconda3\envs\FER\lib\zipfile.py", line 1254, in __init__
    self.fp = io.open(file, filemode)
PermissionError: [Errno 13] Permission denied: 'artifacts\\data'
[2025-09-28 09:57:55,738: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:57:55,741: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:57:55,741: INFO: common]: Directory created at: artifacts
[2025-09-28 09:57:55,743: INFO: common]: Directory created at: artifacts\training
[2025-09-28 09:57:55,810: ERROR: 4016484038]: [Errno 13] Permission denied: 'artifacts\\data'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_19772\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_19772\3037046892.py", line 19, in train
    self.extract_dataset()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_19772\3037046892.py", line 10, in extract_dataset
    with ZipFile(self.config.dataset_path, 'r') as zip_ref:
  File "c:\Users\namnh\miniconda3\envs\FER\lib\zipfile.py", line 1254, in __init__
    self.fp = io.open(file, filemode)
PermissionError: [Errno 13] Permission denied: 'artifacts\\data'
[2025-09-28 09:58:58,626: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 09:58:58,629: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 09:58:58,633: INFO: common]: Directory created at: artifacts
[2025-09-28 09:58:58,635: INFO: common]: Directory created at: artifacts\training
[2025-09-28 09:58:58,721: ERROR: 4016484038]: [Errno 13] Permission denied: 'artifacts\\data'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\3037046892.py", line 19, in train
    self.extract_dataset()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\3037046892.py", line 10, in extract_dataset
    with ZipFile(self.config.dataset_path, 'r') as zip_ref:
  File "c:\Users\namnh\miniconda3\envs\FER\lib\zipfile.py", line 1254, in __init__
    self.fp = io.open(file, filemode)
PermissionError: [Errno 13] Permission denied: 'artifacts\\data'
[2025-09-28 10:00:28,887: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 10:00:28,889: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 10:00:28,890: INFO: common]: Directory created at: artifacts
[2025-09-28 10:00:28,891: INFO: common]: Directory created at: artifacts\training
[2025-09-28 10:00:28,958: ERROR: 4016484038]: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\data'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\983365999.py", line 19, in train
    self.extract_dataset()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\983365999.py", line 9, in extract_dataset
    with ZipFile(self.config.training_data_path, 'r') as zip_ref:
  File "c:\Users\namnh\miniconda3\envs\FER\lib\zipfile.py", line 1254, in __init__
    self.fp = io.open(file, filemode)
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\data_ingestion\\data'
[2025-09-28 10:02:10,318: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 10:02:10,320: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 10:02:10,321: INFO: common]: Directory created at: artifacts
[2025-09-28 10:02:10,322: INFO: common]: Directory created at: artifacts\training
[2025-09-28 10:02:10,397: ERROR: 4016484038]: [Errno 13] Permission denied: 'artifacts\\data_ingestion'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\983365999.py", line 19, in train
    self.extract_dataset()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\983365999.py", line 9, in extract_dataset
    with ZipFile(self.config.training_data_path, 'r') as zip_ref:
  File "c:\Users\namnh\miniconda3\envs\FER\lib\zipfile.py", line 1254, in __init__
    self.fp = io.open(file, filemode)
PermissionError: [Errno 13] Permission denied: 'artifacts\\data_ingestion'
[2025-09-28 10:02:33,712: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 10:02:33,713: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 10:02:33,714: INFO: common]: Directory created at: artifacts
[2025-09-28 10:02:33,715: INFO: common]: Directory created at: artifacts\training
[2025-09-28 10:02:46,426: ERROR: 4016484038]: 'collections.OrderedDict' object has no attribute 'to'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\983365999.py", line 25, in train
    self.model = self.model.to(device)
AttributeError: 'collections.OrderedDict' object has no attribute 'to'
[2025-09-28 10:03:53,345: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 10:03:53,347: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 10:03:53,348: INFO: common]: Directory created at: artifacts
[2025-09-28 10:03:53,349: INFO: common]: Directory created at: artifacts\training
[2025-09-28 10:04:03,614: ERROR: 4016484038]: 'NoneType' object has no attribute 'to'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\3999930852.py", line 25, in train
    self.model = self.get_model().to(device)
AttributeError: 'NoneType' object has no attribute 'to'
[2025-09-28 10:05:10,772: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 10:05:10,774: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 10:05:10,775: INFO: common]: Directory created at: artifacts
[2025-09-28 10:05:10,776: INFO: common]: Directory created at: artifacts\training
[2025-09-28 10:05:20,512: ERROR: 4016484038]: 'collections.OrderedDict' object has no attribute 'to'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\431402426.py", line 27, in train
    self.model = self.model.to(device)
AttributeError: 'collections.OrderedDict' object has no attribute 'to'
[2025-09-28 10:07:04,891: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 10:07:04,893: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 10:07:04,894: INFO: common]: Directory created at: artifacts
[2025-09-28 10:07:04,895: INFO: common]: Directory created at: artifacts\training
[2025-09-28 10:07:05,311: ERROR: 4016484038]: Error(s) in loading state_dict for ResNet:
	size mismatch for fc.weight: copying a param with shape torch.Size([7, 512]) from checkpoint, the shape in current model is torch.Size([1000, 512]).
	size mismatch for fc.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([1000]).
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\4016484038.py", line 5, in <module>
    training.get_model()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16100\366108171.py", line 7, in get_model
    self.model = self.model.load_state_dict(torch.load(self.config.updated_base_model_path))
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	size mismatch for fc.weight: copying a param with shape torch.Size([7, 512]) from checkpoint, the shape in current model is torch.Size([1000, 512]).
	size mismatch for fc.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([1000]).
[2025-09-28 10:15:14,987: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 10:15:14,990: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 10:15:14,992: INFO: common]: Directory created at: artifacts
[2025-09-28 10:15:14,993: INFO: common]: Directory created at: artifacts\training
[2025-09-28 10:16:37,187: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 10:16:37,198: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 10:16:37,199: INFO: common]: Directory created at: artifacts
[2025-09-28 10:16:37,200: INFO: common]: Directory created at: artifacts\training
[2025-09-28 10:26:43,975: INFO: 3183951286]: Model saved at artifacts\training\model.h5
[2025-09-28 10:26:43,987: INFO: 4016484038]: Training completed successfully.
[2025-09-28 15:59:39,719: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-28 15:59:39,722: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 15:59:39,725: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 15:59:39,726: INFO: common]: Directory created at: artifacts
[2025-09-28 15:59:39,726: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-28 15:59:44,324: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-28 15:59:44,325: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-28 15:59:44,325: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-28 15:59:44,325: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-28 15:59:44,327: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 15:59:44,328: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 15:59:44,328: INFO: common]: Directory created at: artifacts
[2025-09-28 15:59:44,329: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-28 15:59:44,329: ERROR: main]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-28 15:59:44,329: ERROR: main]: PrepareBaseModel.get_model() got an unexpected keyword argument 'pretrained'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 21, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    model = self.get_model(pretrained=True)
TypeError: PrepareBaseModel.get_model() got an unexpected keyword argument 'pretrained'
[2025-09-28 15:59:44,329: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-28 15:59:44,331: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 15:59:44,332: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 15:59:44,333: INFO: common]: Directory created at: artifacts
[2025-09-28 15:59:44,333: INFO: common]: Directory created at: artifacts\training
[2025-09-28 16:09:55,091: INFO: training_model]: Model saved at artifacts\training\model.pth
[2025-09-28 16:09:55,112: INFO: main]: >>>>>> stage Training stage completed <<<<<<

x==========x
[2025-09-28 16:58:04,416: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 16:58:04,421: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 16:58:04,422: INFO: common]: Directory created at: artifacts
[2025-09-28 16:58:04,423: INFO: common]: Directory created at: artifacts\training
[2025-09-28 16:58:16,891: ERROR: 4016484038]: unsupported operand type(s) for +: 'WindowsPath' and 'str'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_23844\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_23844\288087573.py", line 39, in train
    train_data = torchvision.datasets.ImageFolder(root=self.config.dataset_path + "/FER2013/train", transform=train_transforms)
TypeError: unsupported operand type(s) for +: 'WindowsPath' and 'str'
[2025-09-28 17:01:49,707: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:01:49,709: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:01:49,710: INFO: common]: Directory created at: artifacts
[2025-09-28 17:01:49,711: INFO: common]: Directory created at: artifacts\training
[2025-09-28 17:09:43,066: INFO: 1622891604]: Model saved at artifacts\training\model.pth
[2025-09-28 17:09:43,080: INFO: 4016484038]: Training completed successfully.
[2025-09-28 17:33:30,711: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:33:30,715: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:33:30,716: INFO: common]: Directory created at: artifacts
[2025-09-28 17:34:27,065: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:34:27,068: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:34:27,069: INFO: common]: Directory created at: artifacts
[2025-09-28 17:35:00,680: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:35:00,683: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:35:00,684: INFO: common]: Directory created at: artifacts
[2025-09-28 17:35:37,251: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:35:37,253: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:35:37,255: INFO: common]: Directory created at: artifacts
[2025-09-28 17:36:47,191: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:36:47,193: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:36:47,194: INFO: common]: Directory created at: artifacts
[2025-09-28 17:36:56,297: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:36:56,299: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:36:56,300: INFO: common]: Directory created at: artifacts
[2025-09-28 17:37:42,114: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:37:42,116: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:37:42,117: INFO: common]: Directory created at: artifacts
[2025-09-28 17:37:59,846: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:37:59,848: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:37:59,850: INFO: common]: Directory created at: artifacts
[2025-09-28 17:38:33,164: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:38:33,166: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:38:33,167: INFO: common]: Directory created at: artifacts
[2025-09-28 17:39:46,391: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:39:46,393: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:39:46,394: INFO: common]: Directory created at: artifacts
[2025-09-28 17:42:02,658: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:42:02,661: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:42:02,662: INFO: common]: Directory created at: artifacts
[2025-09-28 17:42:31,182: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:42:31,184: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:42:31,185: INFO: common]: Directory created at: artifacts
[2025-09-28 17:43:26,014: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:43:26,016: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:43:26,018: INFO: common]: Directory created at: artifacts
[2025-09-28 17:43:48,907: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:43:48,909: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:43:48,911: INFO: common]: Directory created at: artifacts
[2025-09-28 17:46:43,733: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:46:43,735: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:46:43,736: INFO: common]: Directory created at: artifacts
[2025-09-28 17:46:52,386: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:46:52,388: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:46:52,389: INFO: common]: Directory created at: artifacts
[2025-09-28 17:48:37,821: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:48:37,823: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:48:37,824: INFO: common]: Directory created at: artifacts
[2025-09-28 17:53:15,748: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:53:15,750: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:53:15,752: INFO: common]: Directory created at: artifacts
[2025-09-28 17:53:30,941: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:53:30,944: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:53:30,946: INFO: common]: Directory created at: artifacts
[2025-09-28 17:53:56,985: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:53:56,989: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:53:56,990: INFO: common]: Directory created at: artifacts
[2025-09-28 17:54:05,862: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:54:05,863: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:54:05,864: INFO: common]: Directory created at: artifacts
[2025-09-28 17:54:26,076: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:54:26,079: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:54:26,080: INFO: common]: Directory created at: artifacts
[2025-09-28 17:55:14,936: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:55:14,938: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:55:14,939: INFO: common]: Directory created at: artifacts
[2025-09-28 17:55:58,404: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:55:58,406: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:55:58,407: INFO: common]: Directory created at: artifacts
[2025-09-28 17:56:42,621: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:56:42,623: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:56:42,624: INFO: common]: Directory created at: artifacts
[2025-09-28 17:56:57,058: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:56:57,060: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:56:57,061: INFO: common]: Directory created at: artifacts
[2025-09-28 17:57:14,536: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:57:14,538: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:57:14,539: INFO: common]: Directory created at: artifacts
[2025-09-28 17:57:30,865: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:57:30,867: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:57:30,868: INFO: common]: Directory created at: artifacts
[2025-09-28 17:58:06,972: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:58:06,974: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:58:06,975: INFO: common]: Directory created at: artifacts
[2025-09-28 17:58:45,100: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:58:45,102: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:58:45,103: INFO: common]: Directory created at: artifacts
[2025-09-28 17:59:21,569: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 17:59:21,571: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 17:59:21,572: INFO: common]: Directory created at: artifacts
[2025-09-28 18:02:19,508: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:02:19,510: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:02:19,510: INFO: common]: Directory created at: artifacts
[2025-09-28 18:03:03,678: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:03:03,681: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:03:03,682: INFO: common]: Directory created at: artifacts
[2025-09-28 18:04:31,332: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:04:31,335: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:04:31,336: INFO: common]: Directory created at: artifacts
[2025-09-28 18:04:31,338: INFO: common]: Directory created at: artifacts\training
[2025-09-28 18:12:32,516: INFO: 2594059182]: Model saved at artifacts\training\model.pth
[2025-09-28 18:12:32,528: INFO: 4016484038]: Training completed successfully.
[2025-09-28 18:25:56,648: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:25:56,650: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:25:56,651: INFO: common]: Directory created at: artifacts
[2025-09-28 18:26:18,259: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:26:18,261: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:26:18,262: INFO: common]: Directory created at: artifacts
[2025-09-28 18:33:41,070: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:33:41,073: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:33:41,074: INFO: common]: Directory created at: artifacts
[2025-09-28 18:40:44,650: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:40:44,652: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:40:44,653: INFO: common]: Directory created at: artifacts
[2025-09-28 18:44:28,051: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:44:28,053: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:44:28,055: INFO: common]: Directory created at: artifacts
[2025-09-28 18:46:00,807: INFO: common]: JSON file saved at: scores.json
[2025-09-28 18:48:25,842: INFO: _client]: HTTP Request: POST https://dagshub.com/login/oauth/middleman "HTTP/1.1 200 OK"
[2025-09-28 18:48:26,220: INFO: _client]: HTTP Request: POST https://dagshub.com/login/oauth/access_token "HTTP/1.1 200 OK"
[2025-09-28 18:48:26,638: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-28 18:48:26,645: INFO: helpers]: Accessing as nhut-nam
[2025-09-28 18:48:27,131: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-09-28 18:48:27,562: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-28 18:48:27,566: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-09-28 18:48:27,568: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-09-28 18:48:54,888: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:48:54,890: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:48:54,891: INFO: common]: Directory created at: artifacts
[2025-09-28 18:50:27,841: INFO: common]: JSON file saved at: scores.json
[2025-09-28 18:51:14,565: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 18:51:14,566: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 18:51:14,567: INFO: common]: Directory created at: artifacts
[2025-09-28 18:52:46,289: INFO: common]: JSON file saved at: scores.json
[2025-09-28 19:02:01,220: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-28 19:02:01,224: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:02:01,233: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:02:01,233: INFO: common]: Directory created at: artifacts
[2025-09-28 19:02:01,234: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-28 19:02:05,122: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-28 19:02:05,123: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-28 19:02:05,124: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-28 19:02:05,124: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-28 19:02:05,126: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:02:05,127: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:02:05,128: INFO: common]: Directory created at: artifacts
[2025-09-28 19:02:05,128: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-28 19:02:05,128: ERROR: main]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-28 19:02:05,128: ERROR: main]: 'PrepareBaseModelConfig' object has no attribute 'model_name'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 22, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    model = self.get_model(pretrained=True)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 16, in get_model
    if self.config.model_name == "resnet34":
AttributeError: 'PrepareBaseModelConfig' object has no attribute 'model_name'
[2025-09-28 19:02:05,128: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-28 19:02:05,130: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:02:05,131: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:02:05,131: INFO: common]: Directory created at: artifacts
[2025-09-28 19:02:05,132: INFO: common]: Directory created at: artifacts\training
[2025-09-28 19:10:04,849: INFO: training_model]: Model saved at artifacts\training\model.pth
[2025-09-28 19:10:04,866: INFO: main]: >>>>>> stage Training stage completed <<<<<<

x==========x
[2025-09-28 19:10:04,866: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-28 19:10:04,869: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:10:04,871: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:10:04,872: INFO: common]: Directory created at: artifacts
[2025-09-28 19:10:05,175: ERROR: main]: >>>>>> stage Model Evaluation stage failed <<<<<<
[2025-09-28 19:10:05,176: ERROR: main]: Expected state_dict to be dict-like, got <class 'torchvision.models.resnet.ResNet'>.
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 44, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_04_model_evalution_with_mlflow.py", line 15, in main
    model_eval.evaluate()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 19, in evaluate
    self.model = self.load_model(model_path=self.config.path_of_model, params=self.config.all_params)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 79, in load_model
    model.load_state_dict(checkpoint)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\nn\modules\module.py", line 2556, in load_state_dict
    raise TypeError(
TypeError: Expected state_dict to be dict-like, got <class 'torchvision.models.resnet.ResNet'>.
[2025-09-28 19:12:09,939: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-28 19:12:09,942: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:12:09,943: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:12:09,944: INFO: common]: Directory created at: artifacts
[2025-09-28 19:12:09,944: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-28 19:12:13,400: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-28 19:12:13,400: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-28 19:12:13,401: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-28 19:12:13,401: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-28 19:12:13,404: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:12:13,408: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:12:13,409: INFO: common]: Directory created at: artifacts
[2025-09-28 19:12:13,409: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-28 19:12:13,410: ERROR: main]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-28 19:12:13,410: ERROR: main]: 'PrepareBaseModelConfig' object has no attribute 'model_name'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 22, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    model = self.get_model(pretrained=True)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 16, in get_model
    if self.config.model_name == "resnet34":
AttributeError: 'PrepareBaseModelConfig' object has no attribute 'model_name'
[2025-09-28 19:12:13,410: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-28 19:12:13,413: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:12:13,417: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:12:13,418: INFO: common]: Directory created at: artifacts
[2025-09-28 19:12:13,418: INFO: common]: Directory created at: artifacts\training
[2025-09-28 19:19:58,793: INFO: training_model]: Model saved at artifacts\training\model.pth
[2025-09-28 19:19:58,812: INFO: main]: >>>>>> stage Training stage completed <<<<<<

x==========x
[2025-09-28 19:19:58,813: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-28 19:19:58,827: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:19:58,837: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:19:58,838: INFO: common]: Directory created at: artifacts
[2025-09-28 19:24:29,992: INFO: common]: JSON file saved at: scores.json
[2025-09-28 19:24:39,493: INFO: main]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
[2025-09-28 19:28:49,082: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-28 19:28:49,084: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:28:49,093: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:28:49,094: INFO: common]: Directory created at: artifacts
[2025-09-28 19:28:49,094: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-28 19:28:52,919: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-28 19:28:52,920: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-28 19:28:52,920: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-28 19:28:52,920: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-28 19:28:52,925: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:28:52,926: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:28:52,926: INFO: common]: Directory created at: artifacts
[2025-09-28 19:28:52,926: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-28 19:28:52,927: ERROR: main]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-28 19:28:52,927: ERROR: main]: 'PrepareBaseModelConfig' object has no attribute 'model_name'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 22, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    model = self.get_model(pretrained=True)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 16, in get_model
    if self.config.model_name == "resnet34":
AttributeError: 'PrepareBaseModelConfig' object has no attribute 'model_name'
[2025-09-28 19:28:52,928: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-28 19:28:52,932: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:28:52,935: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:28:52,935: INFO: common]: Directory created at: artifacts
[2025-09-28 19:28:52,936: INFO: common]: Directory created at: artifacts\training
[2025-09-28 19:41:00,837: INFO: training_model]: Model saved at artifacts\training\model.pth
[2025-09-28 19:41:00,857: INFO: main]: >>>>>> stage Training stage completed <<<<<<

x==========x
[2025-09-28 19:41:00,857: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-28 19:41:00,859: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:41:00,861: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:41:00,861: INFO: common]: Directory created at: artifacts
[2025-09-28 19:43:34,865: INFO: common]: JSON file saved at: scores.json
[2025-09-28 19:43:44,537: INFO: main]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
[2025-09-28 19:46:50,442: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-28 19:46:50,446: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:46:50,447: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:46:50,447: INFO: common]: Directory created at: artifacts
[2025-09-28 19:46:50,448: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-28 19:46:54,063: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-28 19:46:54,063: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-28 19:46:54,063: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-28 19:46:54,064: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-28 19:46:54,066: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:46:54,068: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:46:54,069: INFO: common]: Directory created at: artifacts
[2025-09-28 19:46:54,069: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-28 19:46:54,069: ERROR: main]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-28 19:46:54,069: ERROR: main]: 'PrepareBaseModelConfig' object has no attribute 'model_name'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 22, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    model = self.get_model(pretrained=True)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 16, in get_model
    if self.config.model_name == "resnet34":
AttributeError: 'PrepareBaseModelConfig' object has no attribute 'model_name'
[2025-09-28 19:46:54,070: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-28 19:46:54,072: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:46:54,074: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:46:54,075: INFO: common]: Directory created at: artifacts
[2025-09-28 19:46:54,075: INFO: common]: Directory created at: artifacts\training
[2025-09-28 19:59:02,765: INFO: training_model]: Model saved at artifacts\training\model.pth
[2025-09-28 19:59:02,782: INFO: main]: >>>>>> stage Training stage completed <<<<<<

x==========x
[2025-09-28 19:59:04,278: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-28 19:59:04,285: INFO: helpers]: Accessing as nhut-nam
[2025-09-28 19:59:04,821: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-09-28 19:59:05,231: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-28 19:59:05,235: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-09-28 19:59:05,235: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-09-28 19:59:05,235: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-28 19:59:05,237: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-28 19:59:05,238: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-28 19:59:05,239: INFO: common]: Directory created at: artifacts
[2025-09-28 20:01:39,121: INFO: common]: JSON file saved at: scores.json
[2025-09-28 20:02:53,895: INFO: main]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
[2025-09-29 08:26:53,794: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-29 08:26:53,806: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 08:26:53,820: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 08:26:53,821: INFO: common]: Directory created at: artifacts
[2025-09-29 11:57:41,348: INFO: stage_01_data_ingestion]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-29 11:57:41,350: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 11:57:41,352: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 11:57:41,353: INFO: common]: Directory created at: artifacts
[2025-09-29 11:57:41,353: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-29 11:57:45,686: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-29 11:57:45,686: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-29 11:57:45,686: INFO: stage_01_data_ingestion]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-29 11:58:13,458: INFO: stage_01_data_ingestion]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-29 11:58:13,461: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 11:58:13,462: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 11:58:13,463: INFO: common]: Directory created at: artifacts
[2025-09-29 11:58:13,463: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-29 11:58:17,198: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-29 11:58:17,198: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-29 11:58:17,199: INFO: stage_01_data_ingestion]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-29 11:59:22,852: INFO: stage_01_data_ingestion]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-29 11:59:22,854: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 11:59:22,856: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 11:59:22,857: INFO: common]: Directory created at: artifacts
[2025-09-29 11:59:22,857: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-29 11:59:26,534: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-29 11:59:26,535: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-29 11:59:26,535: INFO: stage_01_data_ingestion]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-29 12:05:24,522: INFO: stage_01_data_ingestion]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-29 12:05:24,523: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:05:24,525: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:05:24,525: INFO: common]: Directory created at: artifacts
[2025-09-29 12:05:24,525: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-29 12:05:28,011: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-29 12:05:28,012: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-29 12:05:28,012: INFO: stage_01_data_ingestion]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-29 12:05:32,076: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-29 12:05:32,079: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:05:32,080: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:05:32,080: INFO: common]: Directory created at: artifacts
[2025-09-29 12:05:32,081: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-29 12:05:32,081: ERROR: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-29 12:05:32,081: ERROR: stage_02_prepare_base_model]: 'PrepareBaseModelConfig' object has no attribute 'model_name'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 21, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    model = self.get_model(pretrained=True)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 16, in get_model
    if self.config.model_name == "resnet34":
AttributeError: 'PrepareBaseModelConfig' object has no attribute 'model_name'
[2025-09-29 12:05:35,922: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:05:35,924: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:05:35,925: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:05:35,925: INFO: common]: Directory created at: artifacts
[2025-09-29 12:05:35,927: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:07:19,493: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:07:19,494: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:07:19,496: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:07:19,496: INFO: common]: Directory created at: artifacts
[2025-09-29 12:07:19,497: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:09:01,491: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:09:01,493: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:09:01,494: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:09:01,494: INFO: common]: Directory created at: artifacts
[2025-09-29 12:09:01,495: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:11:33,476: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:11:33,478: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:11:33,479: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:11:33,480: INFO: common]: Directory created at: artifacts
[2025-09-29 12:11:33,480: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:17:01,096: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-29 12:17:01,098: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:17:01,100: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:17:01,100: INFO: common]: Directory created at: artifacts
[2025-09-29 12:17:01,101: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-29 12:17:04,540: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-29 12:17:04,541: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-29 12:17:04,541: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-29 12:17:04,541: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-29 12:17:04,542: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:17:04,544: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:17:04,544: INFO: common]: Directory created at: artifacts
[2025-09-29 12:17:04,545: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-29 12:17:04,855: ERROR: main]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-29 12:17:04,855: ERROR: main]: 'NoneType' object has no attribute 'state_dict'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 22, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    self.save_model(model, self.config.updated_base_model_path)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 30, in save_model
    torch.save(model.state_dict(), model_path)
AttributeError: 'NoneType' object has no attribute 'state_dict'
[2025-09-29 12:17:04,856: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:17:04,858: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:17:04,860: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:17:04,860: INFO: common]: Directory created at: artifacts
[2025-09-29 12:17:04,861: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:17:05,179: ERROR: main]: >>>>>> stage Training stage failed <<<<<<
[2025-09-29 12:17:05,180: ERROR: main]: [Errno 2] No such file or directory: 'artifacts\\prepare_base_model\\base_model_updated.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 33, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_03_training_model.py", line 15, in main
    training.get_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 18, in get_model
    self.model.load_state_dict(torch.load(self.config.updated_base_model_path))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\prepare_base_model\\base_model_updated.pth'
[2025-09-29 12:17:05,181: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-29 12:17:05,184: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:17:05,187: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:17:05,187: INFO: common]: Directory created at: artifacts
[2025-09-29 12:17:05,434: ERROR: main]: >>>>>> stage Model Evaluation stage failed <<<<<<
[2025-09-29 12:17:05,434: ERROR: main]: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 44, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_04_model_evalution_with_mlflow.py", line 15, in main
    model_eval.evaluate()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 19, in evaluate
    self.model = self.load_model(model_path=self.config.path_of_model, params=self.config.all_params)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 78, in load_model
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'), weights_only=False)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
[2025-09-29 12:19:53,440: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:19:53,442: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:19:53,444: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:19:53,444: INFO: common]: Directory created at: artifacts
[2025-09-29 12:19:53,444: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:20:05,181: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-29 12:20:05,183: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:20:05,184: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:20:05,185: INFO: common]: Directory created at: artifacts
[2025-09-29 12:20:05,185: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-29 12:20:08,596: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-29 12:20:08,596: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-29 12:20:08,597: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-29 12:20:08,597: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-29 12:20:08,599: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:20:08,601: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:20:08,601: INFO: common]: Directory created at: artifacts
[2025-09-29 12:20:08,602: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-29 12:20:08,895: ERROR: main]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-29 12:20:08,895: ERROR: main]: 'NoneType' object has no attribute 'state_dict'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 22, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    self.save_model(model, self.config.updated_base_model_path)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 30, in save_model
    torch.save(model.state_dict(), model_path)
AttributeError: 'NoneType' object has no attribute 'state_dict'
[2025-09-29 12:20:08,896: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:20:08,899: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:20:08,901: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:20:08,901: INFO: common]: Directory created at: artifacts
[2025-09-29 12:20:08,901: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:20:09,227: ERROR: main]: >>>>>> stage Training stage failed <<<<<<
[2025-09-29 12:20:09,229: ERROR: main]: [Errno 2] No such file or directory: 'artifacts\\prepare_base_model\\base_model_updated.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 33, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_03_training_model.py", line 15, in main
    training.get_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 18, in get_model
    self.model.load_state_dict(torch.load(self.config.updated_base_model_path))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts\\prepare_base_model\\base_model_updated.pth'
[2025-09-29 12:20:09,231: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-29 12:20:09,233: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:20:09,235: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:20:09,236: INFO: common]: Directory created at: artifacts
[2025-09-29 12:20:09,529: ERROR: main]: >>>>>> stage Model Evaluation stage failed <<<<<<
[2025-09-29 12:20:09,529: ERROR: main]: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 44, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_04_model_evalution_with_mlflow.py", line 15, in main
    model_eval.evaluate()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 19, in evaluate
    self.model = self.load_model(model_path=self.config.path_of_model, params=self.config.all_params)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 78, in load_model
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'), weights_only=False)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
[2025-09-29 12:23:37,625: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:23:37,627: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:23:37,629: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:23:37,629: INFO: common]: Directory created at: artifacts
[2025-09-29 12:23:37,629: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:23:49,243: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-29 12:23:49,246: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:23:49,248: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:23:49,248: INFO: common]: Directory created at: artifacts
[2025-09-29 12:23:49,248: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-29 12:23:52,920: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-29 12:23:52,921: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-29 12:23:52,921: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-29 12:23:52,921: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-29 12:23:52,924: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:23:52,926: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:23:52,927: INFO: common]: Directory created at: artifacts
[2025-09-29 12:23:52,927: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-29 12:23:53,289: INFO: main]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-29 12:23:53,289: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:23:53,292: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:23:53,294: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:23:53,294: INFO: common]: Directory created at: artifacts
[2025-09-29 12:23:53,295: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:36:50,132: INFO: training_model]: Model saved at artifacts\training\model.pth
[2025-09-29 12:36:50,147: INFO: main]: >>>>>> stage Training stage completed <<<<<<

x==========x
[2025-09-29 12:36:50,147: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-29 12:36:50,150: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:36:50,153: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:36:50,154: INFO: common]: Directory created at: artifacts
[2025-09-29 12:39:27,533: INFO: common]: JSON file saved at: scores.json
[2025-09-29 12:39:29,391: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-29 12:39:29,397: INFO: helpers]: Accessing as nhut-nam
[2025-09-29 12:39:29,822: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-09-29 12:39:30,220: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-29 12:39:30,224: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-09-29 12:39:30,225: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-09-29 12:40:29,038: INFO: main]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
[2025-09-29 12:40:40,238: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:40:40,241: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:40:40,243: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:40:40,244: INFO: common]: Directory created at: artifacts
[2025-09-29 12:40:40,244: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:42:17,769: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-29 12:42:17,773: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:42:17,775: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:42:17,776: INFO: common]: Directory created at: artifacts
[2025-09-29 12:42:17,776: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-29 12:42:18,234: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-29 12:43:26,981: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:43:26,983: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:43:26,984: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:43:26,984: INFO: common]: Directory created at: artifacts
[2025-09-29 12:43:26,985: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:43:42,213: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-29 12:43:42,215: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:43:42,216: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:43:42,217: INFO: common]: Directory created at: artifacts
[2025-09-29 12:43:42,217: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-29 12:43:42,585: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-29 12:46:18,254: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:46:18,258: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:46:18,260: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:46:18,261: INFO: common]: Directory created at: artifacts
[2025-09-29 12:46:18,261: INFO: common]: Directory created at: artifacts\training
[2025-09-29 12:47:14,464: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-29 12:47:14,466: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:47:14,467: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:47:14,467: INFO: common]: Directory created at: artifacts
[2025-09-29 12:47:14,468: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-29 12:47:14,796: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-29 12:48:49,705: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-29 12:48:49,707: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 12:48:49,709: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 12:48:49,709: INFO: common]: Directory created at: artifacts
[2025-09-29 12:48:49,710: INFO: common]: Directory created at: artifacts\training
[2025-09-29 13:01:12,900: INFO: training_model]: Model saved at artifacts\training\model.pth
[2025-09-29 13:01:12,919: INFO: stage_03_training_model]: >>>>>> stage Training stage completed <<<<<<

x==========x
[2025-09-29 13:25:37,535: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-29 13:25:37,547: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 13:25:37,550: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 13:25:37,550: INFO: common]: Directory created at: artifacts
[2025-09-29 13:32:07,260: INFO: common]: JSON file saved at: scores.json
[2025-09-29 13:32:08,776: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-29 13:32:08,781: INFO: helpers]: Accessing as nhut-nam
[2025-09-29 13:32:09,182: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-09-29 13:32:09,570: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-29 13:32:09,572: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-09-29 13:32:09,573: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-09-29 13:33:11,940: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
[2025-09-29 13:37:15,105: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-29 13:37:15,108: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 13:37:15,109: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 13:37:15,110: INFO: common]: Directory created at: artifacts
[2025-09-29 13:38:50,308: INFO: common]: JSON file saved at: scores.json
[2025-09-29 13:38:51,589: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-29 13:38:51,593: INFO: helpers]: Accessing as nhut-nam
[2025-09-29 13:38:52,046: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-09-29 13:38:52,433: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-29 13:38:52,438: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-09-29 13:38:52,440: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-09-29 13:39:52,818: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
[2025-09-29 13:41:34,127: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-29 13:41:34,129: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-29 13:41:34,130: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-29 13:41:34,131: INFO: common]: Directory created at: artifacts
[2025-09-29 13:43:12,571: INFO: common]: JSON file saved at: scores.json
[2025-09-29 13:43:12,573: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
[2025-09-29 14:11:43,858: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:11:43,858: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:11:58,770: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:11:58] "GET / HTTP/1.1" 200 -
[2025-09-29 14:11:59,030: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:11:59] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
[2025-09-29 14:14:39,176: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:14:39] "GET / HTTP/1.1" 200 -
[2025-09-29 14:14:58,951: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:14:58] "GET / HTTP/1.1" 200 -
[2025-09-29 14:15:43,025: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:15:43,025: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:15:47,232: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:15:47] "GET / HTTP/1.1" 200 -
[2025-09-29 14:15:47,451: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:15:47] "GET / HTTP/1.1" 200 -
[2025-09-29 14:16:42,917: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:16:42] "GET / HTTP/1.1" 200 -
[2025-09-29 14:16:43,269: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:16:43] "GET / HTTP/1.1" 200 -
[2025-09-29 14:16:51,374: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:16:51,374: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:16:54,013: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:16:54] "GET / HTTP/1.1" 200 -
[2025-09-29 14:16:54,246: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:16:54] "GET / HTTP/1.1" 200 -
[2025-09-29 14:19:16,580: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:19:16,580: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:19:18,843: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:19:18] "GET / HTTP/1.1" 200 -
[2025-09-29 14:19:19,072: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:19:19] "GET / HTTP/1.1" 200 -
[2025-09-29 14:19:23,706: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 34, in predict
    decode_image(message, clApp.filename)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\ensure\main.py", line 872, in __call__
    return_val = self.f(*args, **kwargs)
TypeError: decode_image() takes 1 positional argument but 2 were given
[2025-09-29 14:19:23,712: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:19:23] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-09-29 14:19:27,501: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:19:27] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 14:22:56,401: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:22:56,402: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:23:03,111: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:23:03] "GET / HTTP/1.1" 200 -
[2025-09-29 14:23:03,361: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:23:03] "GET / HTTP/1.1" 200 -
[2025-09-29 14:23:03,466: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:23:03] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 14:23:06,811: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 34, in predict
    decode_image(message, clApp.filename)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\utils\common.py", line 119, in decode_image
    imgdata = base64.b64decode(image_base64)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\base64.py", line 87, in b64decode
    return binascii.a2b_base64(s)
binascii.Error: Incorrect padding
[2025-09-29 14:23:06,817: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:23:06] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-09-29 14:29:13,268: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:29:13,268: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:29:15,152: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:29:15] "GET / HTTP/1.1" 200 -
[2025-09-29 14:29:15,376: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:29:15] "GET / HTTP/1.1" 200 -
[2025-09-29 14:29:15,500: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:29:15] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 14:29:19,041: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 34, in predict
    decode_image(message, clApp.filename)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\utils\common.py", line 119, in decode_image
    imgdata = base64.b64decode(image_base64)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\base64.py", line 87, in b64decode
    return binascii.a2b_base64(s)
binascii.Error: Incorrect padding
[2025-09-29 14:29:19,045: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:29:19] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-09-29 14:30:52,689: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:30:52,689: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:30:54,666: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:30:54] "GET / HTTP/1.1" 200 -
[2025-09-29 14:30:54,925: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:30:54] "GET / HTTP/1.1" 200 -
[2025-09-29 14:30:55,003: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:30:55] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 14:30:58,925: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction = clApp.classifier.predict()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'training\\model.pth'
[2025-09-29 14:30:58,930: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:30:58] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-09-29 14:31:47,137: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:31:47,138: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:31:51,071: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:31:51] "GET / HTTP/1.1" 200 -
[2025-09-29 14:31:51,335: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:31:51] "GET / HTTP/1.1" 200 -
[2025-09-29 14:31:51,415: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:31:51] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 14:31:56,077: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 37, in predict
    return jsonify(prediction)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\json\__init__.py", line 170, in jsonify
    return current_app.json.response(*args, **kwargs)  # type: ignore[return-value]
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\json\provider.py", line 214, in response
    f"{self.dumps(obj, **dump_args)}\n", mimetype=self.mimetype
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\json\provider.py", line 179, in dumps
    return json.dumps(obj, **kwargs)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\json\encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\json\encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\json\provider.py", line 121, in _default
    raise TypeError(f"Object of type {type(o).__name__} is not JSON serializable")
TypeError: Object of type ndarray is not JSON serializable
[2025-09-29 14:31:56,085: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:31:56] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-09-29 14:32:47,480: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:32:47,481: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:32:47,940: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:32:47] "GET / HTTP/1.1" 200 -
[2025-09-29 14:32:48,198: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:32:48] "GET / HTTP/1.1" 200 -
[2025-09-29 14:32:48,275: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:32:48] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 14:32:51,289: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:32:51] "POST /predict HTTP/1.1" 200 -
[2025-09-29 14:34:30,616: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 14:34:30,617: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 14:34:31,523: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:34:31] "GET / HTTP/1.1" 200 -
[2025-09-29 14:34:31,764: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:34:31] "GET / HTTP/1.1" 200 -
[2025-09-29 14:34:31,856: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:34:31] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 14:34:37,926: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 14:34:37] "POST /predict HTTP/1.1" 200 -
[2025-09-29 18:52:54,849: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 18:52:54,849: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 18:52:59,099: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:52:59] "GET / HTTP/1.1" 200 -
[2025-09-29 18:52:59,351: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:52:59] "GET / HTTP/1.1" 200 -
[2025-09-29 18:52:59,439: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:52:59] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 18:53:03,563: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 37, in predict
    return jsonify({"prediction": prediction.tolist(), "accuracy": accuracy.tolist()})
AttributeError: 'int' object has no attribute 'tolist'
[2025-09-29 18:53:03,567: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:53:03] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-09-29 18:53:28,028: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 18:53:28,028: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 18:53:35,868: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:53:35] "GET / HTTP/1.1" 200 -
[2025-09-29 18:53:36,087: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:53:36] "GET / HTTP/1.1" 200 -
[2025-09-29 18:53:36,206: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:53:36] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 18:53:39,380: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 37, in predict
    return jsonify({"prediction": prediction.tolist(), "accuracy": accuracy})
AttributeError: 'int' object has no attribute 'tolist'
[2025-09-29 18:53:39,384: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:53:39] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-09-29 18:54:00,174: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 18:54:00,174: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 18:54:01,391: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:54:01] "GET / HTTP/1.1" 200 -
[2025-09-29 18:54:01,654: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:54:01] "GET / HTTP/1.1" 200 -
[2025-09-29 18:54:01,731: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:54:01] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 18:54:04,765: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:54:04] "POST /predict HTTP/1.1" 200 -
[2025-09-29 18:55:57,815: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 18:55:57,815: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 18:55:59,880: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:55:59] "GET / HTTP/1.1" 200 -
[2025-09-29 18:56:00,087: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:00] "GET / HTTP/1.1" 200 -
[2025-09-29 18:56:00,221: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:00] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 18:56:06,988: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:06] "POST /predict HTTP/1.1" 200 -
[2025-09-29 18:56:09,860: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:09] "GET / HTTP/1.1" 200 -
[2025-09-29 18:56:10,127: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:10] "GET / HTTP/1.1" 200 -
[2025-09-29 18:56:10,190: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:10] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 18:56:12,981: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:12] "POST /predict HTTP/1.1" 200 -
[2025-09-29 18:56:24,216: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-09-29 18:56:24,216: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-09-29 18:56:26,438: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:26] "GET / HTTP/1.1" 200 -
[2025-09-29 18:56:26,697: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:26] "GET / HTTP/1.1" 200 -
[2025-09-29 18:56:26,776: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:26] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-09-29 18:56:30,223: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:56:30] "POST /predict HTTP/1.1" 200 -
[2025-09-29 18:57:59,906: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 18:57:59] "POST /predict HTTP/1.1" 200 -
[2025-09-29 19:09:46,158: INFO: _internal]: 127.0.0.1 - - [29/Sep/2025 19:09:46] "POST /predict HTTP/1.1" 200 -
[2025-09-30 18:16:28,735: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:16:28,749: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:16:28,751: INFO: common]: Directory created at: artifacts
[2025-09-30 18:16:28,753: INFO: common]: Directory created at: artifacts\training
[2025-09-30 18:17:49,573: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:17:49,575: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:17:49,576: INFO: common]: Directory created at: artifacts
[2025-09-30 18:17:49,577: INFO: common]: Directory created at: artifacts\training
[2025-09-30 18:24:50,497: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:24:50,508: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:24:50,509: INFO: common]: Directory created at: artifacts
[2025-09-30 18:24:50,511: INFO: common]: Directory created at: artifacts\training
[2025-09-30 18:25:12,766: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:25:12,771: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:25:12,773: INFO: common]: Directory created at: artifacts
[2025-09-30 18:25:12,775: INFO: common]: Directory created at: artifacts\training
[2025-09-30 18:31:35,401: INFO: 1831701381]: Model saved at artifacts\training\model.pth
[2025-09-30 18:31:35,403: INFO: 4016484038]: Training completed successfully.
[2025-09-30 18:34:37,887: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 18:34:37,889: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:34:37,891: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:34:37,891: INFO: common]: Directory created at: artifacts
[2025-09-30 18:34:37,892: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 18:34:38,250: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-30 18:34:42,504: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 18:34:42,507: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:34:42,509: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:34:42,509: INFO: common]: Directory created at: artifacts
[2025-09-30 18:34:42,509: INFO: common]: Directory created at: artifacts\training
[2025-09-30 18:45:30,528: INFO: training_model]: Model saved at artifacts\training\model.pth
[2025-09-30 18:45:30,531: INFO: stage_03_training_model]: >>>>>> stage Training stage completed <<<<<<

x==========x
[2025-09-30 18:45:38,486: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-30 18:45:38,488: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:45:38,489: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:45:38,490: INFO: common]: Directory created at: artifacts
[2025-09-30 18:48:14,963: INFO: common]: JSON file saved at: scores.json
[2025-09-30 18:48:17,409: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-30 18:48:17,419: INFO: helpers]: Accessing as nhut-nam
[2025-09-30 18:48:18,137: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-09-30 18:48:18,532: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-30 18:48:18,540: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-09-30 18:48:18,542: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-09-30 18:49:39,410: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
[2025-09-30 18:55:18,228: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-30 18:55:18,240: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:55:18,242: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:55:18,243: INFO: common]: Directory created at: artifacts
[2025-09-30 18:55:18,243: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-30 18:55:23,157: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-30 18:55:23,158: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-30 18:55:23,158: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-30 18:55:23,158: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 18:55:23,161: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:55:23,162: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:55:23,162: INFO: common]: Directory created at: artifacts
[2025-09-30 18:55:23,163: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 18:55:23,638: INFO: main]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-30 18:55:23,638: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 18:55:23,641: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 18:55:23,643: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 18:55:23,644: INFO: common]: Directory created at: artifacts
[2025-09-30 18:55:23,644: INFO: common]: Directory created at: artifacts\training
[2025-09-30 19:06:29,428: INFO: training_model]: Model saved at artifacts\training\model.pth
[2025-09-30 19:06:29,432: INFO: main]: >>>>>> stage Training stage completed <<<<<<

x==========x
[2025-09-30 19:06:29,433: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-30 19:06:29,435: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:06:29,437: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:06:29,437: INFO: common]: Directory created at: artifacts
[2025-09-30 19:09:07,201: INFO: common]: JSON file saved at: scores.json
[2025-09-30 19:09:09,136: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-30 19:09:09,144: INFO: helpers]: Accessing as nhut-nam
[2025-09-30 19:09:09,605: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-09-30 19:09:10,564: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-09-30 19:09:10,569: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-09-30 19:09:10,570: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-09-30 19:10:14,497: INFO: main]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
[2025-09-30 19:27:55,297: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 19:27:55,299: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:27:55,300: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:27:55,301: INFO: common]: Directory created at: artifacts
[2025-09-30 19:27:55,301: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 19:27:55,301: ERROR: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-30 19:27:55,301: ERROR: stage_02_prepare_base_model]: Model emonext not supported.
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 21, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    model = self.get_model(pretrained=True)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 22, in get_model
    raise ValueError(f"Model {self.config.params_model_name} not supported.")
ValueError: Model emonext not supported.
[2025-09-30 19:27:59,292: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 19:27:59,295: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:27:59,296: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:27:59,297: INFO: common]: Directory created at: artifacts
[2025-09-30 19:27:59,297: INFO: common]: Directory created at: artifacts\training
[2025-09-30 19:28:39,415: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-30 19:28:39,417: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:28:39,419: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:28:39,420: INFO: common]: Directory created at: artifacts
[2025-09-30 19:28:39,420: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-30 19:28:44,911: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-30 19:28:44,913: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-30 19:28:44,913: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-30 19:28:44,913: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 19:28:44,915: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:28:44,917: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:28:44,917: INFO: common]: Directory created at: artifacts
[2025-09-30 19:28:44,918: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 19:28:44,918: ERROR: main]: >>>>>> stage Prepare Base Model stage failed <<<<<<
[2025-09-30 19:28:44,919: ERROR: main]: Model emonext not supported.
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 22, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_02_prepare_base_model.py", line 15, in main
    prepare_base_model.update_base_model()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 26, in update_base_model
    model = self.get_model(pretrained=True)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\prepare_base_model.py", line 22, in get_model
    raise ValueError(f"Model {self.config.params_model_name} not supported.")
ValueError: Model emonext not supported.
[2025-09-30 19:28:44,919: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 19:28:44,921: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:28:44,922: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:28:44,923: INFO: common]: Directory created at: artifacts
[2025-09-30 19:28:44,923: INFO: common]: Directory created at: artifacts\training
[2025-09-30 19:29:00,221: ERROR: main]: >>>>>> stage Training stage failed <<<<<<
[2025-09-30 19:29:00,222: ERROR: main]: 'EmoNeXt' object has no attribute 'fc'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 33, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_03_training_model.py", line 16, in main
    training.train()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 79, in train
    for param in self.model.fc.parameters():
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\nn\modules\module.py", line 1962, in __getattr__
    raise AttributeError(
AttributeError: 'EmoNeXt' object has no attribute 'fc'
[2025-09-30 19:29:00,226: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-30 19:29:00,229: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:29:00,231: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:29:00,232: INFO: common]: Directory created at: artifacts
[2025-09-30 19:29:00,526: ERROR: main]: >>>>>> stage Model Evaluation stage failed <<<<<<
[2025-09-30 19:29:00,526: ERROR: main]: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 44, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_04_model_evalution_with_mlflow.py", line 15, in main
    model_eval.evaluate()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 19, in evaluate
    self.model = self.load_model(model_path=self.config.path_of_model, params=self.config.all_params)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 78, in load_model
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
[2025-09-30 19:29:34,614: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-30 19:29:34,616: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:29:34,617: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:29:34,617: INFO: common]: Directory created at: artifacts
[2025-09-30 19:29:34,617: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-30 19:29:40,726: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-30 19:29:40,727: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-30 19:29:40,727: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-30 19:29:40,727: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 19:29:40,729: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:29:40,731: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:29:40,731: INFO: common]: Directory created at: artifacts
[2025-09-30 19:29:40,732: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 19:29:41,630: INFO: main]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-30 19:29:41,631: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 19:29:41,633: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:29:41,635: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:29:41,635: INFO: common]: Directory created at: artifacts
[2025-09-30 19:29:41,636: INFO: common]: Directory created at: artifacts\training
[2025-09-30 19:29:54,957: ERROR: main]: >>>>>> stage Training stage failed <<<<<<
[2025-09-30 19:29:54,957: ERROR: main]: 'EmoNeXt' object has no attribute 'fc'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 33, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_03_training_model.py", line 16, in main
    training.train()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 79, in train
    for param in self.model.fc.parameters():
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\nn\modules\module.py", line 1962, in __getattr__
    raise AttributeError(
AttributeError: 'EmoNeXt' object has no attribute 'fc'
[2025-09-30 19:29:54,960: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-30 19:29:54,964: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:29:54,966: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:29:54,966: INFO: common]: Directory created at: artifacts
[2025-09-30 19:29:55,253: ERROR: main]: >>>>>> stage Model Evaluation stage failed <<<<<<
[2025-09-30 19:29:55,253: ERROR: main]: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 44, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_04_model_evalution_with_mlflow.py", line 15, in main
    model_eval.evaluate()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 19, in evaluate
    self.model = self.load_model(model_path=self.config.path_of_model, params=self.config.all_params)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 78, in load_model
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
[2025-09-30 19:31:06,171: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-30 19:31:06,173: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:31:06,174: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:31:06,175: INFO: common]: Directory created at: artifacts
[2025-09-30 19:31:06,175: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-30 19:31:11,799: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-30 19:31:11,800: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-30 19:31:11,800: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-30 19:31:11,800: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 19:31:11,805: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:31:11,807: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:31:11,807: INFO: common]: Directory created at: artifacts
[2025-09-30 19:31:11,808: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 19:31:12,529: INFO: main]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-30 19:31:12,530: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 19:31:12,532: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:31:12,535: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:31:12,535: INFO: common]: Directory created at: artifacts
[2025-09-30 19:31:12,535: INFO: common]: Directory created at: artifacts\training
[2025-09-30 19:31:26,109: ERROR: main]: >>>>>> stage Training stage failed <<<<<<
[2025-09-30 19:31:26,109: ERROR: main]: 'module' object is not callable
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 33, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_03_training_model.py", line 16, in main
    training.train()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 90, in train
    train_loss, train_accuracy = self.train_epoch()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 113, in train_epoch
    pbar = tqdm(unit="batch", file=sys.stdout, total=len(self.train_loader))
TypeError: 'module' object is not callable
[2025-09-30 19:31:26,123: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-30 19:31:26,126: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:31:26,128: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:31:26,128: INFO: common]: Directory created at: artifacts
[2025-09-30 19:31:26,380: ERROR: main]: >>>>>> stage Model Evaluation stage failed <<<<<<
[2025-09-30 19:31:26,380: ERROR: main]: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 44, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_04_model_evalution_with_mlflow.py", line 15, in main
    model_eval.evaluate()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 19, in evaluate
    self.model = self.load_model(model_path=self.config.path_of_model, params=self.config.all_params)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 78, in load_model
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
[2025-09-30 19:34:51,755: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 19:34:51,757: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:34:51,758: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:34:51,759: INFO: common]: Directory created at: artifacts
[2025-09-30 19:34:51,759: INFO: common]: Directory created at: artifacts\training
[2025-09-30 19:36:11,136: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-30 19:36:11,139: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:36:11,140: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:36:11,141: INFO: common]: Directory created at: artifacts
[2025-09-30 19:36:11,141: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-30 19:36:17,007: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-30 19:36:17,008: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-30 19:36:17,008: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-30 19:36:17,008: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 19:36:17,010: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:36:17,012: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:36:17,012: INFO: common]: Directory created at: artifacts
[2025-09-30 19:36:17,012: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 19:36:17,743: INFO: main]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-30 19:36:17,743: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 19:36:17,746: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:36:17,748: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:36:17,748: INFO: common]: Directory created at: artifacts
[2025-09-30 19:36:17,749: INFO: common]: Directory created at: artifacts\training
[2025-09-30 19:36:30,954: ERROR: main]: >>>>>> stage Training stage failed <<<<<<
[2025-09-30 19:36:30,954: ERROR: main]: name 'device' is not defined
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 33, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_03_training_model.py", line 16, in main
    training.train()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 80, in train
    self.model = self.model.to(device)
NameError: name 'device' is not defined
[2025-09-30 19:36:30,957: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-30 19:36:30,960: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:36:30,961: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:36:30,962: INFO: common]: Directory created at: artifacts
[2025-09-30 19:36:31,230: ERROR: main]: >>>>>> stage Model Evaluation stage failed <<<<<<
[2025-09-30 19:36:31,231: ERROR: main]: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 44, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_04_model_evalution_with_mlflow.py", line 15, in main
    model_eval.evaluate()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 19, in evaluate
    self.model = self.load_model(model_path=self.config.path_of_model, params=self.config.all_params)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 78, in load_model
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
[2025-09-30 19:37:57,700: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-30 19:37:57,702: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:37:57,704: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:37:57,704: INFO: common]: Directory created at: artifacts
[2025-09-30 19:37:57,704: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-30 19:38:03,211: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-30 19:38:03,211: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-30 19:38:03,212: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-30 19:38:03,212: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 19:38:03,213: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:38:03,215: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:38:03,215: INFO: common]: Directory created at: artifacts
[2025-09-30 19:38:03,216: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 19:38:03,968: INFO: main]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-30 19:38:03,968: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 19:38:03,971: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:38:03,974: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:38:03,975: INFO: common]: Directory created at: artifacts
[2025-09-30 19:38:03,975: INFO: common]: Directory created at: artifacts\training
[2025-09-30 19:38:17,738: ERROR: main]: >>>>>> stage Training stage failed <<<<<<
[2025-09-30 19:38:17,739: ERROR: main]: 'Training' object has no attribute 'amp'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 33, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_03_training_model.py", line 16, in main
    training.train()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 90, in train
    train_loss, train_accuracy = self.train_epoch()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 120, in train_epoch
    with torch.autocast(self.device.type, enabled=self.amp):
AttributeError: 'Training' object has no attribute 'amp'
[2025-09-30 19:38:17,747: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-30 19:38:17,750: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:38:17,751: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:38:17,752: INFO: common]: Directory created at: artifacts
[2025-09-30 19:38:18,044: ERROR: main]: >>>>>> stage Model Evaluation stage failed <<<<<<
[2025-09-30 19:38:18,044: ERROR: main]: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 44, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_04_model_evalution_with_mlflow.py", line 15, in main
    model_eval.evaluate()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 19, in evaluate
    self.model = self.load_model(model_path=self.config.path_of_model, params=self.config.all_params)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 78, in load_model
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
[2025-09-30 19:39:01,452: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-30 19:39:01,456: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:39:01,458: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:39:01,458: INFO: common]: Directory created at: artifacts
[2025-09-30 19:39:01,458: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-30 19:39:07,106: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-30 19:39:07,107: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-30 19:39:07,107: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-30 19:39:07,108: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 19:39:07,111: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:39:07,115: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:39:07,115: INFO: common]: Directory created at: artifacts
[2025-09-30 19:39:07,116: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 19:39:07,867: INFO: main]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-30 19:39:07,867: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 19:39:07,870: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:39:07,872: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:39:07,872: INFO: common]: Directory created at: artifacts
[2025-09-30 19:39:07,873: INFO: common]: Directory created at: artifacts\training
[2025-09-30 19:39:28,976: ERROR: main]: >>>>>> stage Training stage failed <<<<<<
[2025-09-30 19:39:28,983: ERROR: main]: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 33, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_03_training_model.py", line 16, in main
    training.train()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 90, in train
    train_loss, train_accuracy = self.train_epoch()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\training_model.py", line 122, in train_epoch
    loss = self.criterion(outputs, labels)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\nn\modules\loss.py", line 1310, in forward
    return F.cross_entropy(
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\nn\functional.py", line 3462, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
TypeError: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not tuple
[2025-09-30 19:39:29,073: INFO: main]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-09-30 19:39:29,085: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:39:29,088: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:39:29,090: INFO: common]: Directory created at: artifacts
[2025-09-30 19:39:29,427: ERROR: main]: >>>>>> stage Model Evaluation stage failed <<<<<<
[2025-09-30 19:39:29,428: ERROR: main]: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
Traceback (most recent call last):
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\main.py", line 44, in <module>
    obj.main()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\pipeline\stage_04_model_evalution_with_mlflow.py", line 15, in main
    model_eval.evaluate()
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 19, in evaluate
    self.model = self.load_model(model_path=self.config.path_of_model, params=self.config.all_params)
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\src\FacialExpressionRecognition\components\model_evalution_with_mlflow.py", line 78, in load_model
    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 1484, in load
    with _open_file_like(f, "rb") as opened_file:
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 759, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "C:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\serialization.py", line 740, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'artifacts/training/model.pth'
[2025-09-30 19:42:04,396: INFO: main]: >>>>>> stage Data Ingestion stage started <<<<<<
[2025-09-30 19:42:04,400: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:42:04,401: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:42:04,402: INFO: common]: Directory created at: artifacts
[2025-09-30 19:42:04,402: INFO: common]: Directory created at: artifacts/data_ingestion
[2025-09-30 19:42:10,154: INFO: data_ingestion]: Downloaded file from :[https://drive.google.com/file/d/10cuSJ1L8N5CT5cmLvieyCf5TFtEz1lLy/view?usp=sharing] and saved at :[artifacts/data_ingestion/data.zip]
[2025-09-30 19:42:10,154: INFO: data_ingestion]: Zip file already extracted in dir :[artifacts/data_ingestion]
[2025-09-30 19:42:10,155: INFO: main]: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x
[2025-09-30 19:42:10,155: INFO: main]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-09-30 19:42:10,157: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:42:10,158: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:42:10,158: INFO: common]: Directory created at: artifacts
[2025-09-30 19:42:10,158: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-09-30 19:42:10,927: INFO: main]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-09-30 19:42:10,927: INFO: main]: >>>>>> stage Training stage started <<<<<<
[2025-09-30 19:42:10,929: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-09-30 19:42:10,931: INFO: common]: yaml file: params.yaml loaded successfully
[2025-09-30 19:42:10,932: INFO: common]: Directory created at: artifacts
[2025-09-30 19:42:10,932: INFO: common]: Directory created at: artifacts\training
[2025-10-13 18:46:14,256: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-10-13 18:46:14,269: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 18:46:14,273: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 18:46:14,273: INFO: common]: Directory created at: artifacts
[2025-10-13 18:46:14,275: INFO: common]: Directory created at: artifacts\training
[2025-10-13 18:48:03,145: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage started <<<<<<
[2025-10-13 18:48:03,149: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 18:48:03,152: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 18:48:03,152: INFO: common]: Directory created at: artifacts
[2025-10-13 18:48:03,153: INFO: common]: Directory created at: artifacts/prepare_base_model
[2025-10-13 18:48:03,949: INFO: stage_02_prepare_base_model]: >>>>>> stage Prepare Base Model stage completed <<<<<<

x==========x
[2025-10-13 18:48:08,177: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-10-13 18:48:08,178: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 18:48:08,180: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 18:48:08,180: INFO: common]: Directory created at: artifacts
[2025-10-13 18:48:08,180: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:01:35,780: INFO: stage_03_training_model]: >>>>>> stage Training stage started <<<<<<
[2025-10-13 19:01:35,782: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:01:35,783: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:01:35,784: INFO: common]: Directory created at: artifacts
[2025-10-13 19:01:35,784: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:28:59,367: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:28:59,370: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:28:59,371: INFO: common]: Directory created at: artifacts
[2025-10-13 19:28:59,373: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:29:09,630: ERROR: 4016484038]: 'module' object is not callable
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_5252\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_5252\3197379545.py", line 81, in train
    train_loss, train_accuracy = self.train_epoch()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_5252\3197379545.py", line 103, in train_epoch
    pbar = tqdm(unit="batch", file=sys.stdout, total=len(self.train_loader))
TypeError: 'module' object is not callable
[2025-10-13 19:32:35,824: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:32:35,826: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:32:35,827: INFO: common]: Directory created at: artifacts
[2025-10-13 19:32:35,828: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:33:14,650: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:33:14,652: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:33:14,653: INFO: common]: Directory created at: artifacts
[2025-10-13 19:33:14,654: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:35:37,945: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:35:37,946: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:35:37,948: INFO: common]: Directory created at: artifacts
[2025-10-13 19:35:37,949: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:38:08,506: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:38:08,509: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:38:08,511: INFO: common]: Directory created at: artifacts
[2025-10-13 19:38:08,512: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:44:40,107: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:44:40,109: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:44:40,110: INFO: common]: Directory created at: artifacts
[2025-10-13 19:44:40,111: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:45:05,458: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:45:05,461: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:45:05,462: INFO: common]: Directory created at: artifacts
[2025-10-13 19:45:05,463: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:53:11,505: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:53:11,507: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:53:11,508: INFO: common]: Directory created at: artifacts
[2025-10-13 19:53:11,510: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:56:16,029: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:56:16,031: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:56:16,032: INFO: common]: Directory created at: artifacts
[2025-10-13 19:56:16,033: INFO: common]: Directory created at: artifacts\training
[2025-10-13 19:59:57,320: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 19:59:57,322: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 19:59:57,323: INFO: common]: Directory created at: artifacts
[2025-10-13 19:59:57,324: INFO: common]: Directory created at: artifacts\training
[2025-10-13 20:01:06,649: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 20:01:06,652: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 20:01:06,653: INFO: common]: Directory created at: artifacts
[2025-10-13 20:01:06,654: INFO: common]: Directory created at: artifacts\training
[2025-10-13 20:01:17,816: ERROR: 4016484038]: Numpy is not available
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_17672\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_17672\3825442364.py", line 98, in train
    train_loss, train_accuracy = self.train_epoch()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_17672\3825442364.py", line 121, in train_epoch
    for batch_idx, data in enumerate(self.train_loader):
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torchvision\transforms\transforms.py", line 137, in __call__
    return F.to_tensor(pic)
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torchvision\transforms\functional.py", line 166, in to_tensor
    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))
RuntimeError: Numpy is not available
[2025-10-13 20:04:02,016: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 20:04:02,020: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 20:04:02,021: INFO: common]: Directory created at: artifacts
[2025-10-13 20:04:02,023: INFO: common]: Directory created at: artifacts\training
[2025-10-13 20:04:13,547: ERROR: 4016484038]: Numpy is not available
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_964\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_964\3825442364.py", line 98, in train
    train_loss, train_accuracy = self.train_epoch()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_964\3825442364.py", line 121, in train_epoch
    for batch_idx, data in enumerate(self.train_loader):
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\utils\data\dataloader.py", line 633, in __next__
    data = self._next_data()
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\utils\data\dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torch\utils\data\_utils\fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torchvision\datasets\folder.py", line 231, in __getitem__
    sample = self.transform(sample)
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torchvision\transforms\transforms.py", line 137, in __call__
    return F.to_tensor(pic)
  File "c:\Users\namnh\miniconda3\envs\FER\lib\site-packages\torchvision\transforms\functional.py", line 166, in to_tensor
    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))
RuntimeError: Numpy is not available
[2025-10-13 20:46:19,088: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 20:46:19,091: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 20:46:19,092: INFO: common]: Directory created at: artifacts
[2025-10-13 20:46:19,093: INFO: common]: Directory created at: artifacts\training
[2025-10-13 20:50:40,927: ERROR: 4016484038]: CrossEntropyLoss.forward() got an unexpected keyword argument 'label_smoothing'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21460\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21460\303971276.py", line 98, in train
    val_loss, val_accuracy = self.val_epoch()
                             ^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_21460\303971276.py", line 161, in val_epoch
    loss = self.criterion(outputs, labels, label_smoothing=0.2)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: CrossEntropyLoss.forward() got an unexpected keyword argument 'label_smoothing'
[2025-10-13 21:01:25,750: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:01:25,751: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:01:25,752: INFO: common]: Directory created at: artifacts
[2025-10-13 21:01:25,753: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:02:25,253: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:02:25,255: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:02:25,256: INFO: common]: Directory created at: artifacts
[2025-10-13 21:02:25,256: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:07:12,474: INFO: 3193822386]: Epoch [1/100], Train Loss: 1.9286, Train Accuracy: 23.55%, Val Loss: 1.9360, Val Accuracy: 24.07%
[2025-10-13 21:07:12,474: ERROR: 4016484038]: 'Training' object has no attribute 'best_val_accuracy'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_13496\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_13496\3193822386.py", line 100, in train
    if val_accuracy > self.best_val_accuracy:
                      ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Training' object has no attribute 'best_val_accuracy'
[2025-10-13 21:22:37,685: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:22:37,696: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:22:37,697: INFO: common]: Directory created at: artifacts
[2025-10-13 21:22:37,698: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:22:49,622: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:22:49,624: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:22:49,625: INFO: common]: Directory created at: artifacts
[2025-10-13 21:22:49,626: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:27:33,526: INFO: 1160106751]: Epoch [1/100], Train Loss: 1.8730, Train Accuracy: 24.68%, Val Loss: 1.8718, Val Accuracy: 24.94%
[2025-10-13 21:27:33,675: INFO: 1160106751]: Model saved at artifacts\training\model.pth
[2025-10-13 21:28:22,710: INFO: 1160106751]: Epoch [2/100], Train Loss: 1.8695, Train Accuracy: 25.09%, Val Loss: 1.8714, Val Accuracy: 24.94%
[2025-10-13 21:29:11,771: INFO: 1160106751]: Epoch [3/100], Train Loss: 1.8688, Train Accuracy: 25.12%, Val Loss: 1.8738, Val Accuracy: 24.94%
[2025-10-13 21:30:00,983: INFO: 1160106751]: Epoch [4/100], Train Loss: 1.8682, Train Accuracy: 25.13%, Val Loss: 1.8753, Val Accuracy: 24.94%
[2025-10-13 21:30:50,007: INFO: 1160106751]: Epoch [5/100], Train Loss: 1.8680, Train Accuracy: 25.12%, Val Loss: 1.8737, Val Accuracy: 24.94%
[2025-10-13 21:31:38,249: INFO: 1160106751]: Epoch [6/100], Train Loss: 1.8680, Train Accuracy: 25.13%, Val Loss: 1.8741, Val Accuracy: 24.94%
[2025-10-13 21:32:26,735: INFO: 1160106751]: Epoch [7/100], Train Loss: 1.8679, Train Accuracy: 25.14%, Val Loss: 1.8719, Val Accuracy: 24.94%
[2025-10-13 21:33:46,306: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:33:46,319: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:33:46,321: INFO: common]: Directory created at: artifacts
[2025-10-13 21:33:46,322: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:33:58,272: ERROR: 4016484038]: shape '[-1, 1960]' is invalid for input of size 1866240
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9268\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9268\2239188907.py", line 98, in train
    train_loss, train_accuracy = self.train_epoch()
                                 ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9268\2239188907.py", line 128, in train_epoch
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 251, in forward
    x = self.stn(x)
        ^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 228, in stn
    xs = xs.view(-1, 10 * 14 * 14)
         ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 1960]' is invalid for input of size 1866240
[2025-10-13 21:35:33,621: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:35:33,624: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:35:33,625: INFO: common]: Directory created at: artifacts
[2025-10-13 21:35:33,626: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:35:44,731: ERROR: 4016484038]: shape '[-1, 1960]' is invalid for input of size 1866240
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_10816\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_10816\2239188907.py", line 98, in train
    train_loss, train_accuracy = self.train_epoch()
                                 ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_10816\2239188907.py", line 128, in train_epoch
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 251, in forward
    x = self.stn(x)
        ^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 228, in stn
    xs = xs.view(-1, 10 * 14 * 14)
         ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 1960]' is invalid for input of size 1866240
[2025-10-13 21:36:18,159: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:36:18,161: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:36:18,162: INFO: common]: Directory created at: artifacts
[2025-10-13 21:36:18,163: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:41:31,673: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:41:31,686: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:41:31,687: INFO: common]: Directory created at: artifacts
[2025-10-13 21:41:31,688: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:41:43,282: ERROR: 4016484038]: shape '[-1, 27040]' is invalid for input of size 138240
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12344\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12344\2380135849.py", line 98, in train
    train_loss, train_accuracy = self.train_epoch()
                                 ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12344\2380135849.py", line 128, in train_epoch
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 251, in forward
    x = self.stn(x)
        ^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 228, in stn
    xs = xs.view(-1, 10 * 52 * 52)
         ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 27040]' is invalid for input of size 138240
[2025-10-13 21:42:11,045: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:42:11,046: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:42:11,048: INFO: common]: Directory created at: artifacts
[2025-10-13 21:42:11,048: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:42:21,916: ERROR: 4016484038]: shape '[-1, 27040]' is invalid for input of size 138240
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12344\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12344\2380135849.py", line 98, in train
    train_loss, train_accuracy = self.train_epoch()
                                 ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_12344\2380135849.py", line 128, in train_epoch
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 251, in forward
    x = self.stn(x)
        ^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 228, in stn
    xs = xs.view(-1, 10 * 14 * 14)
         ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 27040]' is invalid for input of size 138240
[2025-10-13 21:42:46,372: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 21:42:46,374: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 21:42:46,375: INFO: common]: Directory created at: artifacts
[2025-10-13 21:42:46,376: INFO: common]: Directory created at: artifacts\training
[2025-10-13 21:47:25,004: INFO: 2380135849]: Epoch [1/100], Train Loss: 1.8732, Train Accuracy: 24.89%, Val Loss: 1.8777, Val Accuracy: 24.94%
[2025-10-13 21:47:25,140: INFO: 2380135849]: Model saved at artifacts\training\model.pth
[2025-10-13 21:48:06,796: INFO: 2380135849]: Epoch [2/100], Train Loss: 1.8697, Train Accuracy: 25.11%, Val Loss: 1.8751, Val Accuracy: 24.94%
[2025-10-13 21:48:49,191: INFO: 2380135849]: Epoch [3/100], Train Loss: 1.8681, Train Accuracy: 25.18%, Val Loss: 1.8738, Val Accuracy: 24.94%
[2025-10-13 21:49:29,729: INFO: 2380135849]: Epoch [4/100], Train Loss: 1.8680, Train Accuracy: 25.05%, Val Loss: 1.8715, Val Accuracy: 24.94%
[2025-10-13 21:50:10,958: INFO: 2380135849]: Epoch [5/100], Train Loss: 1.8700, Train Accuracy: 25.01%, Val Loss: 1.8739, Val Accuracy: 24.94%
[2025-10-13 22:11:03,917: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 22:11:03,921: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 22:11:03,922: INFO: common]: Directory created at: artifacts
[2025-10-13 22:11:03,923: INFO: common]: Directory created at: artifacts\training
[2025-10-13 22:11:16,591: ERROR: 4016484038]: cross_entropy() missing 2 required positional arguments: 'input' and 'target'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_6960\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_6960\784947823.py", line 91, in train
    self.criterion = torch.nn.functional.cross_entropy()
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cross_entropy() missing 2 required positional arguments: 'input' and 'target'
[2025-10-13 22:11:53,313: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 22:11:53,315: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 22:11:53,316: INFO: common]: Directory created at: artifacts
[2025-10-13 22:11:53,317: INFO: common]: Directory created at: artifacts\training
[2025-10-13 22:12:03,975: ERROR: 4016484038]: cross_entropy() missing 2 required positional arguments: 'input' and 'target'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_6960\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_6960\3556565605.py", line 91, in train
    self.criterion = torch.nn.functional.cross_entropy()
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cross_entropy() missing 2 required positional arguments: 'input' and 'target'
[2025-10-13 22:12:39,250: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 22:12:39,252: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 22:12:39,253: INFO: common]: Directory created at: artifacts
[2025-10-13 22:12:39,254: INFO: common]: Directory created at: artifacts\training
[2025-10-13 22:18:08,741: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 22:18:08,743: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 22:18:08,744: INFO: common]: Directory created at: artifacts
[2025-10-13 22:18:08,745: INFO: common]: Directory created at: artifacts\training
[2025-10-13 22:18:48,546: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-13 22:18:48,548: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-13 22:18:48,550: INFO: common]: Directory created at: artifacts
[2025-10-13 22:18:48,551: INFO: common]: Directory created at: artifacts\training
[2025-10-14 13:36:39,202: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 13:36:39,215: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 13:36:39,216: INFO: common]: Directory created at: artifacts
[2025-10-14 13:36:39,217: INFO: common]: Directory created at: artifacts\training
[2025-10-14 13:43:02,444: INFO: 2892123983]: Epoch [1/100], Train Loss: 1.8599, Train Accuracy: 25.62%, Val Loss: 1.7673, Val Accuracy: 37.03%
[2025-10-14 13:43:02,590: INFO: 2892123983]: Model saved at artifacts\training\model.pth
[2025-10-14 13:44:40,345: INFO: 2892123983]: Epoch [2/100], Train Loss: 1.8198, Train Accuracy: 29.16%, Val Loss: 1.6419, Val Accuracy: 44.13%
[2025-10-14 13:44:40,481: INFO: 2892123983]: Model saved at artifacts\training\model.pth
[2025-10-14 13:46:17,852: INFO: 2892123983]: Epoch [3/100], Train Loss: 1.7924, Train Accuracy: 31.70%, Val Loss: 1.5807, Val Accuracy: 48.04%
[2025-10-14 13:46:17,991: INFO: 2892123983]: Model saved at artifacts\training\model.pth
[2025-10-14 13:48:39,185: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 13:48:39,200: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 13:48:39,201: INFO: common]: Directory created at: artifacts
[2025-10-14 13:48:39,201: INFO: common]: Directory created at: artifacts\training
[2025-10-14 13:55:25,385: INFO: 325663613]: Epoch [1/100], Train Loss: 1.6675, Train Accuracy: 41.41%, Val Loss: 1.5028, Val Accuracy: 52.94%
[2025-10-14 13:55:25,613: INFO: 325663613]: Model saved at artifacts\training\model.pth
[2025-10-14 13:55:25,931: ERROR: 4016484038]: 'Training' object has no attribute 'amp'
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_952\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_952\325663613.py", line 114, in train
    self.test_model()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_952\325663613.py", line 196, in test_model
    with torch.autocast(self.device.type, enabled=self.amp):
                                                  ^^^^^^^^
AttributeError: 'Training' object has no attribute 'amp'
[2025-10-14 14:00:45,353: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 14:00:45,354: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 14:00:45,355: INFO: common]: Directory created at: artifacts
[2025-10-14 14:00:45,356: INFO: common]: Directory created at: artifacts\training
[2025-10-14 14:01:08,214: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 14:01:08,216: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 14:01:08,218: INFO: common]: Directory created at: artifacts
[2025-10-14 14:01:08,219: INFO: common]: Directory created at: artifacts\training
[2025-10-14 14:07:40,686: INFO: 733562757]: Epoch [1/100], Train Loss: 1.6692, Train Accuracy: 41.03%, Val Loss: 1.5095, Val Accuracy: 53.11%
[2025-10-14 14:07:40,914: INFO: 733562757]: Model saved at artifacts\training\model.pth
[2025-10-14 14:07:44,480: ERROR: 4016484038]: too many values to unpack (expected 2)
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9768\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9768\733562757.py", line 114, in train
    self.test_model()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_9768\733562757.py", line 197, in test_model
    _, logits = self.model(inputs)
    ^^^^^^^^^
ValueError: too many values to unpack (expected 2)
[2025-10-14 14:12:53,341: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 14:12:53,352: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 14:12:53,356: INFO: common]: Directory created at: artifacts
[2025-10-14 14:12:53,358: INFO: common]: Directory created at: artifacts\training
[2025-10-14 14:19:34,302: INFO: 3924460229]: Epoch [1/100], Train Loss: 1.6593, Train Accuracy: 42.15%, Val Loss: 1.4925, Val Accuracy: 54.86%
[2025-10-14 14:19:34,542: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:19:46,174: ERROR: 4016484038]: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.31 GiB is allocated by PyTorch, and 259.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_23076\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_23076\3924460229.py", line 114, in train
    self.test_model()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_23076\3924460229.py", line 197, in test_model
    logits = self.model(inputs)
             ^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 247, in forward
    x = self.forward_features(x)
        ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 239, in forward_features
    x = self.downsample_layers[i](x)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\container.py", line 244, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 92, in forward
    x = self.weight[:, None, None] * x + self.bias[:, None, None]
        ~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 12.31 GiB is allocated by PyTorch, and 259.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[2025-10-14 14:25:18,719: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 14:25:18,731: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 14:25:18,731: INFO: common]: Directory created at: artifacts
[2025-10-14 14:25:18,734: INFO: common]: Directory created at: artifacts\training
[2025-10-14 14:25:33,208: ERROR: 4016484038]: shape '[-1, 9000]' is invalid for input of size 188160
Traceback (most recent call last):
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16044\4016484038.py", line 6, in <module>
    training.train()
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16044\3924460229.py", line 98, in train
    train_loss, train_accuracy = self.train_epoch()
                                 ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\AppData\Local\Temp\ipykernel_16044\3924460229.py", line 130, in train_epoch
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 246, in forward
    x = self.stn(x)
        ^^^^^^^^^^^
  File "c:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 228, in stn
    xs = xs.view(-1, 10 * 30 * 30)
         ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 9000]' is invalid for input of size 188160
[2025-10-14 14:25:52,480: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 14:25:52,486: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 14:25:52,487: INFO: common]: Directory created at: artifacts
[2025-10-14 14:25:52,488: INFO: common]: Directory created at: artifacts\training
[2025-10-14 14:31:51,825: INFO: 3924460229]: Epoch [1/100], Train Loss: 1.8038, Train Accuracy: 30.63%, Val Loss: 1.7855, Val Accuracy: 34.94%
[2025-10-14 14:31:52,042: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:34:23,866: INFO: 3924460229]: Epoch [2/100], Train Loss: 1.7291, Train Accuracy: 37.55%, Val Loss: 1.7118, Val Accuracy: 38.87%
[2025-10-14 14:34:24,007: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:36:23,835: INFO: 3924460229]: Epoch [3/100], Train Loss: 1.6880, Train Accuracy: 41.07%, Val Loss: 1.6719, Val Accuracy: 42.85%
[2025-10-14 14:36:23,965: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:38:26,143: INFO: 3924460229]: Epoch [4/100], Train Loss: 1.6566, Train Accuracy: 42.64%, Val Loss: 1.6293, Val Accuracy: 45.22%
[2025-10-14 14:38:26,268: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:40:14,087: INFO: 3924460229]: Epoch [5/100], Train Loss: 1.6339, Train Accuracy: 44.19%, Val Loss: 1.6222, Val Accuracy: 44.75%
[2025-10-14 14:42:02,248: INFO: 3924460229]: Epoch [6/100], Train Loss: 1.6210, Train Accuracy: 45.21%, Val Loss: 1.6051, Val Accuracy: 46.31%
[2025-10-14 14:42:02,376: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:43:54,978: INFO: 3924460229]: Epoch [7/100], Train Loss: 1.6023, Train Accuracy: 46.31%, Val Loss: 1.5948, Val Accuracy: 47.78%
[2025-10-14 14:43:55,109: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:44:15,297: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 14:44:15,298: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 14:44:59,257: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 14:44:59] "GET / HTTP/1.1" 200 -
[2025-10-14 14:44:59,428: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 14:44:59] "GET / HTTP/1.1" 200 -
[2025-10-14 14:44:59,661: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 14:44:59] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
[2025-10-14 14:46:01,149: INFO: 3924460229]: Epoch [8/100], Train Loss: 1.5939, Train Accuracy: 47.44%, Val Loss: 1.5786, Val Accuracy: 47.98%
[2025-10-14 14:46:01,271: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:46:57,012: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 14:46:57,012: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 14:47:01,753: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 14:47:01] "GET / HTTP/1.1" 200 -
[2025-10-14 14:47:01,984: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 14:47:01] "GET / HTTP/1.1" 200 -
[2025-10-14 14:47:57,361: INFO: 3924460229]: Epoch [9/100], Train Loss: 1.5843, Train Accuracy: 47.83%, Val Loss: 1.5800, Val Accuracy: 48.23%
[2025-10-14 14:47:57,476: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:48:31,130: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 14:48:31,130: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 14:48:32,913: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 14:48:32] "GET / HTTP/1.1" 200 -
[2025-10-14 14:48:33,147: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 14:48:33] "GET / HTTP/1.1" 200 -
[2025-10-14 14:48:34,640: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 14:48:34] "[33mGET /camera HTTP/1.1[0m" 404 -
[2025-10-14 14:49:45,606: INFO: 3924460229]: Epoch [10/100], Train Loss: 1.5750, Train Accuracy: 48.80%, Val Loss: 1.5693, Val Accuracy: 48.51%
[2025-10-14 14:49:45,732: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:51:37,508: INFO: 3924460229]: Epoch [11/100], Train Loss: 1.5671, Train Accuracy: 49.09%, Val Loss: 1.5580, Val Accuracy: 49.87%
[2025-10-14 14:51:37,628: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:53:27,566: INFO: 3924460229]: Epoch [12/100], Train Loss: 1.5590, Train Accuracy: 49.63%, Val Loss: 1.5555, Val Accuracy: 49.71%
[2025-10-14 14:55:24,279: INFO: 3924460229]: Epoch [13/100], Train Loss: 1.5504, Train Accuracy: 50.34%, Val Loss: 1.5451, Val Accuracy: 50.82%
[2025-10-14 14:55:24,406: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 14:57:21,493: INFO: 3924460229]: Epoch [14/100], Train Loss: 1.5435, Train Accuracy: 50.69%, Val Loss: 1.5530, Val Accuracy: 50.40%
[2025-10-14 14:59:19,503: INFO: 3924460229]: Epoch [15/100], Train Loss: 1.5388, Train Accuracy: 51.09%, Val Loss: 1.5594, Val Accuracy: 50.15%
[2025-10-14 15:01:14,447: INFO: 3924460229]: Epoch [16/100], Train Loss: 1.5306, Train Accuracy: 51.67%, Val Loss: 1.5395, Val Accuracy: 50.96%
[2025-10-14 15:01:14,563: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 15:03:04,449: INFO: 3924460229]: Epoch [17/100], Train Loss: 1.5274, Train Accuracy: 51.60%, Val Loss: 1.5252, Val Accuracy: 52.33%
[2025-10-14 15:03:04,588: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 15:04:53,091: INFO: 3924460229]: Epoch [18/100], Train Loss: 1.5195, Train Accuracy: 52.23%, Val Loss: 1.5460, Val Accuracy: 50.91%
[2025-10-14 15:06:47,619: INFO: 3924460229]: Epoch [19/100], Train Loss: 1.5180, Train Accuracy: 52.64%, Val Loss: 1.5233, Val Accuracy: 53.00%
[2025-10-14 15:06:47,760: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 15:08:45,053: INFO: 3924460229]: Epoch [20/100], Train Loss: 1.5126, Train Accuracy: 52.64%, Val Loss: 1.5285, Val Accuracy: 51.55%
[2025-10-14 15:10:42,039: INFO: 3924460229]: Epoch [21/100], Train Loss: 1.5065, Train Accuracy: 53.06%, Val Loss: 1.5311, Val Accuracy: 52.66%
[2025-10-14 15:12:39,924: INFO: 3924460229]: Epoch [22/100], Train Loss: 1.5072, Train Accuracy: 53.22%, Val Loss: 1.5206, Val Accuracy: 52.66%
[2025-10-14 15:14:36,527: INFO: 3924460229]: Epoch [23/100], Train Loss: 1.4998, Train Accuracy: 54.01%, Val Loss: 1.5127, Val Accuracy: 52.63%
[2025-10-14 15:16:33,366: INFO: 3924460229]: Epoch [24/100], Train Loss: 1.4952, Train Accuracy: 54.10%, Val Loss: 1.5255, Val Accuracy: 52.35%
[2025-10-14 15:18:30,540: INFO: 3924460229]: Epoch [25/100], Train Loss: 1.4917, Train Accuracy: 54.40%, Val Loss: 1.5198, Val Accuracy: 52.58%
[2025-10-14 15:20:27,682: INFO: 3924460229]: Epoch [26/100], Train Loss: 1.4901, Train Accuracy: 54.24%, Val Loss: 1.4949, Val Accuracy: 53.86%
[2025-10-14 15:20:27,816: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 15:22:25,241: INFO: 3924460229]: Epoch [27/100], Train Loss: 1.4808, Train Accuracy: 54.91%, Val Loss: 1.5189, Val Accuracy: 52.94%
[2025-10-14 15:24:23,721: INFO: 3924460229]: Epoch [28/100], Train Loss: 1.4802, Train Accuracy: 55.47%, Val Loss: 1.5110, Val Accuracy: 52.91%
[2025-10-14 15:26:21,504: INFO: 3924460229]: Epoch [29/100], Train Loss: 1.4759, Train Accuracy: 55.30%, Val Loss: 1.5236, Val Accuracy: 52.47%
[2025-10-14 15:28:20,555: INFO: 3924460229]: Epoch [30/100], Train Loss: 1.4731, Train Accuracy: 55.59%, Val Loss: 1.5010, Val Accuracy: 53.75%
[2025-10-14 15:30:19,806: INFO: 3924460229]: Epoch [31/100], Train Loss: 1.4653, Train Accuracy: 56.04%, Val Loss: 1.5144, Val Accuracy: 53.72%
[2025-10-14 15:32:18,591: INFO: 3924460229]: Epoch [32/100], Train Loss: 1.4656, Train Accuracy: 56.16%, Val Loss: 1.4827, Val Accuracy: 54.56%
[2025-10-14 15:32:18,714: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 15:34:45,247: INFO: 3924460229]: Epoch [33/100], Train Loss: 1.4619, Train Accuracy: 56.58%, Val Loss: 1.5036, Val Accuracy: 53.30%
[2025-10-14 15:41:57,588: INFO: 3924460229]: Epoch [34/100], Train Loss: 1.4605, Train Accuracy: 56.53%, Val Loss: 1.4945, Val Accuracy: 55.34%
[2025-10-14 15:41:57,730: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 15:43:54,401: INFO: 3924460229]: Epoch [35/100], Train Loss: 1.4501, Train Accuracy: 57.27%, Val Loss: 1.4904, Val Accuracy: 54.44%
[2025-10-14 15:45:52,073: INFO: 3924460229]: Epoch [36/100], Train Loss: 1.4491, Train Accuracy: 57.40%, Val Loss: 1.5013, Val Accuracy: 54.11%
[2025-10-14 15:47:49,249: INFO: 3924460229]: Epoch [37/100], Train Loss: 1.4491, Train Accuracy: 56.91%, Val Loss: 1.4924, Val Accuracy: 54.56%
[2025-10-14 15:49:47,057: INFO: 3924460229]: Epoch [38/100], Train Loss: 1.4458, Train Accuracy: 57.51%, Val Loss: 1.4992, Val Accuracy: 54.72%
[2025-10-14 15:51:44,429: INFO: 3924460229]: Epoch [39/100], Train Loss: 1.4450, Train Accuracy: 57.68%, Val Loss: 1.4904, Val Accuracy: 54.89%
[2025-10-14 15:53:41,301: INFO: 3924460229]: Epoch [40/100], Train Loss: 1.4369, Train Accuracy: 57.92%, Val Loss: 1.4912, Val Accuracy: 55.22%
[2025-10-14 15:55:37,901: INFO: 3924460229]: Epoch [41/100], Train Loss: 1.4342, Train Accuracy: 58.18%, Val Loss: 1.5000, Val Accuracy: 54.67%
[2025-10-14 15:57:34,657: INFO: 3924460229]: Epoch [42/100], Train Loss: 1.4319, Train Accuracy: 58.37%, Val Loss: 1.4894, Val Accuracy: 54.67%
[2025-10-14 15:59:31,321: INFO: 3924460229]: Epoch [43/100], Train Loss: 1.4199, Train Accuracy: 59.33%, Val Loss: 1.4885, Val Accuracy: 55.70%
[2025-10-14 15:59:31,448: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 16:01:28,522: INFO: 3924460229]: Epoch [44/100], Train Loss: 1.4266, Train Accuracy: 58.85%, Val Loss: 1.5085, Val Accuracy: 53.89%
[2025-10-14 16:03:25,079: INFO: 3924460229]: Epoch [45/100], Train Loss: 1.4240, Train Accuracy: 58.98%, Val Loss: 1.4922, Val Accuracy: 54.05%
[2025-10-14 16:05:20,776: INFO: 3924460229]: Epoch [46/100], Train Loss: 1.4191, Train Accuracy: 59.52%, Val Loss: 1.4863, Val Accuracy: 55.50%
[2025-10-14 16:07:17,688: INFO: 3924460229]: Epoch [47/100], Train Loss: 1.4146, Train Accuracy: 59.73%, Val Loss: 1.5044, Val Accuracy: 54.69%
[2025-10-14 16:09:14,100: INFO: 3924460229]: Epoch [48/100], Train Loss: 1.4144, Train Accuracy: 59.49%, Val Loss: 1.4816, Val Accuracy: 55.31%
[2025-10-14 16:11:10,492: INFO: 3924460229]: Epoch [49/100], Train Loss: 1.4098, Train Accuracy: 59.69%, Val Loss: 1.4922, Val Accuracy: 55.11%
[2025-10-14 16:13:08,150: INFO: 3924460229]: Epoch [50/100], Train Loss: 1.4101, Train Accuracy: 59.65%, Val Loss: 1.4814, Val Accuracy: 56.37%
[2025-10-14 16:13:08,282: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 16:15:05,341: INFO: 3924460229]: Epoch [51/100], Train Loss: 1.4062, Train Accuracy: 60.22%, Val Loss: 1.4991, Val Accuracy: 54.58%
[2025-10-14 16:17:02,318: INFO: 3924460229]: Epoch [52/100], Train Loss: 1.3993, Train Accuracy: 60.68%, Val Loss: 1.4936, Val Accuracy: 55.48%
[2025-10-14 16:18:58,831: INFO: 3924460229]: Epoch [53/100], Train Loss: 1.3949, Train Accuracy: 60.71%, Val Loss: 1.4904, Val Accuracy: 55.28%
[2025-10-14 16:20:55,722: INFO: 3924460229]: Epoch [54/100], Train Loss: 1.3968, Train Accuracy: 60.82%, Val Loss: 1.4821, Val Accuracy: 55.75%
[2025-10-14 16:22:47,689: INFO: 3924460229]: Epoch [55/100], Train Loss: 1.3881, Train Accuracy: 61.28%, Val Loss: 1.5021, Val Accuracy: 54.92%
[2025-10-14 16:24:36,057: INFO: 3924460229]: Epoch [56/100], Train Loss: 1.3895, Train Accuracy: 61.41%, Val Loss: 1.4741, Val Accuracy: 55.45%
[2025-10-14 16:26:26,573: INFO: 3924460229]: Epoch [57/100], Train Loss: 1.3843, Train Accuracy: 61.41%, Val Loss: 1.5002, Val Accuracy: 54.92%
[2025-10-14 16:28:25,063: INFO: 3924460229]: Epoch [58/100], Train Loss: 1.3762, Train Accuracy: 61.96%, Val Loss: 1.4888, Val Accuracy: 55.08%
[2025-10-14 16:30:22,805: INFO: 3924460229]: Epoch [59/100], Train Loss: 1.3784, Train Accuracy: 61.91%, Val Loss: 1.4879, Val Accuracy: 55.59%
[2025-10-14 16:32:21,311: INFO: 3924460229]: Epoch [60/100], Train Loss: 1.3735, Train Accuracy: 62.61%, Val Loss: 1.4838, Val Accuracy: 56.03%
[2025-10-14 16:34:18,139: INFO: 3924460229]: Epoch [61/100], Train Loss: 1.3704, Train Accuracy: 62.75%, Val Loss: 1.4747, Val Accuracy: 56.48%
[2025-10-14 16:34:18,314: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 16:36:16,221: INFO: 3924460229]: Epoch [62/100], Train Loss: 1.3666, Train Accuracy: 62.71%, Val Loss: 1.4932, Val Accuracy: 56.00%
[2025-10-14 16:38:14,273: INFO: 3924460229]: Epoch [63/100], Train Loss: 1.3620, Train Accuracy: 63.04%, Val Loss: 1.4736, Val Accuracy: 57.34%
[2025-10-14 16:38:14,390: INFO: 3924460229]: Model saved at artifacts\training\model.pth
[2025-10-14 16:40:12,539: INFO: 3924460229]: Epoch [64/100], Train Loss: 1.3684, Train Accuracy: 63.14%, Val Loss: 1.4859, Val Accuracy: 56.34%
[2025-10-14 16:42:10,862: INFO: 3924460229]: Epoch [65/100], Train Loss: 1.3605, Train Accuracy: 63.13%, Val Loss: 1.4856, Val Accuracy: 55.84%
[2025-10-14 16:44:08,677: INFO: 3924460229]: Epoch [66/100], Train Loss: 1.3535, Train Accuracy: 63.72%, Val Loss: 1.4904, Val Accuracy: 54.78%
[2025-10-14 16:46:06,784: INFO: 3924460229]: Epoch [67/100], Train Loss: 1.3539, Train Accuracy: 63.62%, Val Loss: 1.4682, Val Accuracy: 56.65%
[2025-10-14 16:48:05,018: INFO: 3924460229]: Epoch [68/100], Train Loss: 1.3454, Train Accuracy: 64.16%, Val Loss: 1.4875, Val Accuracy: 56.92%
[2025-10-14 16:50:01,917: INFO: 3924460229]: Epoch [69/100], Train Loss: 1.3493, Train Accuracy: 63.80%, Val Loss: 1.4838, Val Accuracy: 56.67%
[2025-10-14 16:51:59,665: INFO: 3924460229]: Epoch [70/100], Train Loss: 1.3408, Train Accuracy: 64.63%, Val Loss: 1.4754, Val Accuracy: 56.51%
[2025-10-14 16:53:56,738: INFO: 3924460229]: Epoch [71/100], Train Loss: 1.3388, Train Accuracy: 65.08%, Val Loss: 1.4766, Val Accuracy: 56.31%
[2025-10-14 16:55:55,274: INFO: 3924460229]: Epoch [72/100], Train Loss: 1.3357, Train Accuracy: 64.85%, Val Loss: 1.4804, Val Accuracy: 56.56%
[2025-10-14 16:58:02,818: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 16:58:02,818: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 16:58:05,224: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 16:58:05] "GET / HTTP/1.1" 200 -
[2025-10-14 16:58:05,450: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 16:58:05] "GET / HTTP/1.1" 200 -
[2025-10-14 16:58:13,360: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 16:58:13,360: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 16:58:13] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 16:58:16,318: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 16:58:16,319: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 16:58:16] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 16:58:17,466: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 16:58:17] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 16:59:33,745: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 16:59:33,745: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 16:59:47,796: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 16:59:47,797: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 16:59:49,912: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 16:59:49] "GET / HTTP/1.1" 200 -
[2025-10-14 16:59:50,169: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 16:59:50] "GET / HTTP/1.1" 200 -
[2025-10-14 16:59:50,247: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 16:59:50] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 16:59:54,645: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 16:59:54,650: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 16:59:54] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:01:39,338: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:01:39,339: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:01:40,865: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:01:40] "GET / HTTP/1.1" 200 -
[2025-10-14 17:01:41,118: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:01:41] "GET / HTTP/1.1" 200 -
[2025-10-14 17:01:41,194: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:01:41] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:01:44,586: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 17:01:44,586: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:01:44] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:02:24,080: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:02:24,080: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:02:25,134: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:02:25] "GET / HTTP/1.1" 200 -
[2025-10-14 17:02:25,383: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:02:25] "GET / HTTP/1.1" 200 -
[2025-10-14 17:02:25,473: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:02:25] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:02:29,525: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 17:02:29,525: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:02:29] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:03:30,775: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:03:30,775: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:03:32,113: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:03:32] "GET / HTTP/1.1" 200 -
[2025-10-14 17:03:32,352: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:03:32] "GET / HTTP/1.1" 200 -
[2025-10-14 17:03:32,448: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:03:32] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:03:35,812: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 17:03:35,812: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:03:35] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:04:01,351: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:04:01,351: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:04:02,915: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:04:02] "GET / HTTP/1.1" 200 -
[2025-10-14 17:04:03,182: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:04:03] "GET / HTTP/1.1" 200 -
[2025-10-14 17:04:03,247: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:04:03] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:04:06,137: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 17:04:06,142: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:04:06] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:04:49,771: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:04:49,771: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:04:52,794: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:04:52] "GET / HTTP/1.1" 200 -
[2025-10-14 17:04:53,058: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:04:53] "GET / HTTP/1.1" 200 -
[2025-10-14 17:04:53,134: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:04:53] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:04:56,278: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 17:04:56,283: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:04:56] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:05:41,271: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:05:41,271: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:05:43,179: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:05:43] "GET / HTTP/1.1" 200 -
[2025-10-14 17:05:43,429: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:05:43] "GET / HTTP/1.1" 200 -
[2025-10-14 17:05:43,515: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:05:43] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:05:46,317: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 17:05:46,322: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:05:46] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:07:05,230: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:07:05,230: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:07:08,400: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:07:08] "GET / HTTP/1.1" 200 -
[2025-10-14 17:07:08,659: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:07:08] "GET / HTTP/1.1" 200 -
[2025-10-14 17:07:08,750: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:07:08] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:07:11,950: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 14, in predict
    model.load_state_dict(torch.load(os.path.join("artifacts/training", "model.pth")))
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for ResNet:
	Missing key(s) in state_dict: "conv1.weight", "bn1.weight", "bn1.bias", "bn1.running_mean", "bn1.running_var", "layer1.0.conv1.weight", "layer1.0.bn1.weight", "layer1.0.bn1.bias", "layer1.0.bn1.running_mean", "layer1.0.bn1.running_var", "layer1.0.conv2.weight", "layer1.0.bn2.weight", "layer1.0.bn2.bias", "layer1.0.bn2.running_mean", "layer1.0.bn2.running_var", "layer1.1.conv1.weight", "layer1.1.bn1.weight", "layer1.1.bn1.bias", "layer1.1.bn1.running_mean", "layer1.1.bn1.running_var", "layer1.1.conv2.weight", "layer1.1.bn2.weight", "layer1.1.bn2.bias", "layer1.1.bn2.running_mean", "layer1.1.bn2.running_var", "layer1.2.conv1.weight", "layer1.2.bn1.weight", "layer1.2.bn1.bias", "layer1.2.bn1.running_mean", "layer1.2.bn1.running_var", "layer1.2.conv2.weight", "layer1.2.bn2.weight", "layer1.2.bn2.bias", "layer1.2.bn2.running_mean", "layer1.2.bn2.running_var", "layer2.0.conv1.weight", "layer2.0.bn1.weight", "layer2.0.bn1.bias", "layer2.0.bn1.running_mean", "layer2.0.bn1.running_var", "layer2.0.conv2.weight", "layer2.0.bn2.weight", "layer2.0.bn2.bias", "layer2.0.bn2.running_mean", "layer2.0.bn2.running_var", "layer2.0.downsample.0.weight", "layer2.0.downsample.1.weight", "layer2.0.downsample.1.bias", "layer2.0.downsample.1.running_mean", "layer2.0.downsample.1.running_var", "layer2.1.conv1.weight", "layer2.1.bn1.weight", "layer2.1.bn1.bias", "layer2.1.bn1.running_mean", "layer2.1.bn1.running_var", "layer2.1.conv2.weight", "layer2.1.bn2.weight", "layer2.1.bn2.bias", "layer2.1.bn2.running_mean", "layer2.1.bn2.running_var", "layer2.2.conv1.weight", "layer2.2.bn1.weight", "layer2.2.bn1.bias", "layer2.2.bn1.running_mean", "layer2.2.bn1.running_var", "layer2.2.conv2.weight", "layer2.2.bn2.weight", "layer2.2.bn2.bias", "layer2.2.bn2.running_mean", "layer2.2.bn2.running_var", "layer2.3.conv1.weight", "layer2.3.bn1.weight", "layer2.3.bn1.bias", "layer2.3.bn1.running_mean", "layer2.3.bn1.running_var", "layer2.3.conv2.weight", "layer2.3.bn2.weight", "layer2.3.bn2.bias", "layer2.3.bn2.running_mean", "layer2.3.bn2.running_var", "layer3.0.conv1.weight", "layer3.0.bn1.weight", "layer3.0.bn1.bias", "layer3.0.bn1.running_mean", "layer3.0.bn1.running_var", "layer3.0.conv2.weight", "layer3.0.bn2.weight", "layer3.0.bn2.bias", "layer3.0.bn2.running_mean", "layer3.0.bn2.running_var", "layer3.0.downsample.0.weight", "layer3.0.downsample.1.weight", "layer3.0.downsample.1.bias", "layer3.0.downsample.1.running_mean", "layer3.0.downsample.1.running_var", "layer3.1.conv1.weight", "layer3.1.bn1.weight", "layer3.1.bn1.bias", "layer3.1.bn1.running_mean", "layer3.1.bn1.running_var", "layer3.1.conv2.weight", "layer3.1.bn2.weight", "layer3.1.bn2.bias", "layer3.1.bn2.running_mean", "layer3.1.bn2.running_var", "layer3.2.conv1.weight", "layer3.2.bn1.weight", "layer3.2.bn1.bias", "layer3.2.bn1.running_mean", "layer3.2.bn1.running_var", "layer3.2.conv2.weight", "layer3.2.bn2.weight", "layer3.2.bn2.bias", "layer3.2.bn2.running_mean", "layer3.2.bn2.running_var", "layer3.3.conv1.weight", "layer3.3.bn1.weight", "layer3.3.bn1.bias", "layer3.3.bn1.running_mean", "layer3.3.bn1.running_var", "layer3.3.conv2.weight", "layer3.3.bn2.weight", "layer3.3.bn2.bias", "layer3.3.bn2.running_mean", "layer3.3.bn2.running_var", "layer3.4.conv1.weight", "layer3.4.bn1.weight", "layer3.4.bn1.bias", "layer3.4.bn1.running_mean", "layer3.4.bn1.running_var", "layer3.4.conv2.weight", "layer3.4.bn2.weight", "layer3.4.bn2.bias", "layer3.4.bn2.running_mean", "layer3.4.bn2.running_var", "layer3.5.conv1.weight", "layer3.5.bn1.weight", "layer3.5.bn1.bias", "layer3.5.bn1.running_mean", "layer3.5.bn1.running_var", "layer3.5.conv2.weight", "layer3.5.bn2.weight", "layer3.5.bn2.bias", "layer3.5.bn2.running_mean", "layer3.5.bn2.running_var", "layer4.0.conv1.weight", "layer4.0.bn1.weight", "layer4.0.bn1.bias", "layer4.0.bn1.running_mean", "layer4.0.bn1.running_var", "layer4.0.conv2.weight", "layer4.0.bn2.weight", "layer4.0.bn2.bias", "layer4.0.bn2.running_mean", "layer4.0.bn2.running_var", "layer4.0.downsample.0.weight", "layer4.0.downsample.1.weight", "layer4.0.downsample.1.bias", "layer4.0.downsample.1.running_mean", "layer4.0.downsample.1.running_var", "layer4.1.conv1.weight", "layer4.1.bn1.weight", "layer4.1.bn1.bias", "layer4.1.bn1.running_mean", "layer4.1.bn1.running_var", "layer4.1.conv2.weight", "layer4.1.bn2.weight", "layer4.1.bn2.bias", "layer4.1.bn2.running_mean", "layer4.1.bn2.running_var", "layer4.2.conv1.weight", "layer4.2.bn1.weight", "layer4.2.bn1.bias", "layer4.2.bn1.running_mean", "layer4.2.bn1.running_var", "layer4.2.conv2.weight", "layer4.2.bn2.weight", "layer4.2.bn2.bias", "layer4.2.bn2.running_mean", "layer4.2.bn2.running_var", "fc.weight", "fc.bias". 
	Unexpected key(s) in state_dict: "localization.0.weight", "localization.0.bias", "localization.1.weight", "localization.1.bias", "localization.1.running_mean", "localization.1.running_var", "localization.1.num_batches_tracked", "localization.4.weight", "localization.4.bias", "localization.5.weight", "localization.5.bias", "localization.5.running_mean", "localization.5.running_var", "localization.5.num_batches_tracked", "fc_loc.0.weight", "fc_loc.0.bias", "fc_loc.2.weight", "fc_loc.2.bias", "downsample_layers.0.0.weight", "downsample_layers.0.0.bias", "downsample_layers.0.1.weight", "downsample_layers.0.1.bias", "downsample_layers.1.0.weight", "downsample_layers.1.0.bias", "downsample_layers.1.1.weight", "downsample_layers.1.1.bias", "downsample_layers.1.2.fc.0.weight", "downsample_layers.1.2.fc.2.weight", "downsample_layers.2.0.weight", "downsample_layers.2.0.bias", "downsample_layers.2.1.weight", "downsample_layers.2.1.bias", "downsample_layers.2.2.fc.0.weight", "downsample_layers.2.2.fc.2.weight", "downsample_layers.3.0.weight", "downsample_layers.3.0.bias", "downsample_layers.3.1.weight", "downsample_layers.3.1.bias", "downsample_layers.3.2.fc.0.weight", "downsample_layers.3.2.fc.2.weight", "stages.0.0.gamma", "stages.0.0.dwconv.weight", "stages.0.0.dwconv.bias", "stages.0.0.norm.weight", "stages.0.0.norm.bias", "stages.0.0.pwconv1.weight", "stages.0.0.pwconv1.bias", "stages.0.0.pwconv2.weight", "stages.0.0.pwconv2.bias", "stages.0.1.gamma", "stages.0.1.dwconv.weight", "stages.0.1.dwconv.bias", "stages.0.1.norm.weight", "stages.0.1.norm.bias", "stages.0.1.pwconv1.weight", "stages.0.1.pwconv1.bias", "stages.0.1.pwconv2.weight", "stages.0.1.pwconv2.bias", "stages.0.2.gamma", "stages.0.2.dwconv.weight", "stages.0.2.dwconv.bias", "stages.0.2.norm.weight", "stages.0.2.norm.bias", "stages.0.2.pwconv1.weight", "stages.0.2.pwconv1.bias", "stages.0.2.pwconv2.weight", "stages.0.2.pwconv2.bias", "stages.1.0.gamma", "stages.1.0.dwconv.weight", "stages.1.0.dwconv.bias", "stages.1.0.norm.weight", "stages.1.0.norm.bias", "stages.1.0.pwconv1.weight", "stages.1.0.pwconv1.bias", "stages.1.0.pwconv2.weight", "stages.1.0.pwconv2.bias", "stages.1.1.gamma", "stages.1.1.dwconv.weight", "stages.1.1.dwconv.bias", "stages.1.1.norm.weight", "stages.1.1.norm.bias", "stages.1.1.pwconv1.weight", "stages.1.1.pwconv1.bias", "stages.1.1.pwconv2.weight", "stages.1.1.pwconv2.bias", "stages.1.2.gamma", "stages.1.2.dwconv.weight", "stages.1.2.dwconv.bias", "stages.1.2.norm.weight", "stages.1.2.norm.bias", "stages.1.2.pwconv1.weight", "stages.1.2.pwconv1.bias", "stages.1.2.pwconv2.weight", "stages.1.2.pwconv2.bias", "stages.2.0.gamma", "stages.2.0.dwconv.weight", "stages.2.0.dwconv.bias", "stages.2.0.norm.weight", "stages.2.0.norm.bias", "stages.2.0.pwconv1.weight", "stages.2.0.pwconv1.bias", "stages.2.0.pwconv2.weight", "stages.2.0.pwconv2.bias", "stages.2.1.gamma", "stages.2.1.dwconv.weight", "stages.2.1.dwconv.bias", "stages.2.1.norm.weight", "stages.2.1.norm.bias", "stages.2.1.pwconv1.weight", "stages.2.1.pwconv1.bias", "stages.2.1.pwconv2.weight", "stages.2.1.pwconv2.bias", "stages.2.2.gamma", "stages.2.2.dwconv.weight", "stages.2.2.dwconv.bias", "stages.2.2.norm.weight", "stages.2.2.norm.bias", "stages.2.2.pwconv1.weight", "stages.2.2.pwconv1.bias", "stages.2.2.pwconv2.weight", "stages.2.2.pwconv2.bias", "stages.2.3.gamma", "stages.2.3.dwconv.weight", "stages.2.3.dwconv.bias", "stages.2.3.norm.weight", "stages.2.3.norm.bias", "stages.2.3.pwconv1.weight", "stages.2.3.pwconv1.bias", "stages.2.3.pwconv2.weight", "stages.2.3.pwconv2.bias", "stages.2.4.gamma", "stages.2.4.dwconv.weight", "stages.2.4.dwconv.bias", "stages.2.4.norm.weight", "stages.2.4.norm.bias", "stages.2.4.pwconv1.weight", "stages.2.4.pwconv1.bias", "stages.2.4.pwconv2.weight", "stages.2.4.pwconv2.bias", "stages.2.5.gamma", "stages.2.5.dwconv.weight", "stages.2.5.dwconv.bias", "stages.2.5.norm.weight", "stages.2.5.norm.bias", "stages.2.5.pwconv1.weight", "stages.2.5.pwconv1.bias", "stages.2.5.pwconv2.weight", "stages.2.5.pwconv2.bias", "stages.2.6.gamma", "stages.2.6.dwconv.weight", "stages.2.6.dwconv.bias", "stages.2.6.norm.weight", "stages.2.6.norm.bias", "stages.2.6.pwconv1.weight", "stages.2.6.pwconv1.bias", "stages.2.6.pwconv2.weight", "stages.2.6.pwconv2.bias", "stages.2.7.gamma", "stages.2.7.dwconv.weight", "stages.2.7.dwconv.bias", "stages.2.7.norm.weight", "stages.2.7.norm.bias", "stages.2.7.pwconv1.weight", "stages.2.7.pwconv1.bias", "stages.2.7.pwconv2.weight", "stages.2.7.pwconv2.bias", "stages.2.8.gamma", "stages.2.8.dwconv.weight", "stages.2.8.dwconv.bias", "stages.2.8.norm.weight", "stages.2.8.norm.bias", "stages.2.8.pwconv1.weight", "stages.2.8.pwconv1.bias", "stages.2.8.pwconv2.weight", "stages.2.8.pwconv2.bias", "stages.3.0.gamma", "stages.3.0.dwconv.weight", "stages.3.0.dwconv.bias", "stages.3.0.norm.weight", "stages.3.0.norm.bias", "stages.3.0.pwconv1.weight", "stages.3.0.pwconv1.bias", "stages.3.0.pwconv2.weight", "stages.3.0.pwconv2.bias", "stages.3.1.gamma", "stages.3.1.dwconv.weight", "stages.3.1.dwconv.bias", "stages.3.1.norm.weight", "stages.3.1.norm.bias", "stages.3.1.pwconv1.weight", "stages.3.1.pwconv1.bias", "stages.3.1.pwconv2.weight", "stages.3.1.pwconv2.bias", "stages.3.2.gamma", "stages.3.2.dwconv.weight", "stages.3.2.dwconv.bias", "stages.3.2.norm.weight", "stages.3.2.norm.bias", "stages.3.2.pwconv1.weight", "stages.3.2.pwconv1.bias", "stages.3.2.pwconv2.weight", "stages.3.2.pwconv2.bias", "norm.weight", "norm.bias", "head.weight", "head.bias". 
[2025-10-14 17:07:11,950: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:07:11] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:10:33,038: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:10:33,038: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:10:36,917: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:10:36] "GET / HTTP/1.1" 200 -
[2025-10-14 17:10:37,173: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:10:37] "GET / HTTP/1.1" 200 -
[2025-10-14 17:10:37,252: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:10:37] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:10:41,766: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 24, in predict
    output = model(image)
             ^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 246, in forward
    x = self.stn(x)
        ^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 228, in stn
    xs = xs.view(-1, 10 * 14 * 14)
         ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 1960]' is invalid for input of size 29160
[2025-10-14 17:10:41,766: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:10:41] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:11:03,945: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:11:03,945: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:11:05,496: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:11:05] "GET / HTTP/1.1" 200 -
[2025-10-14 17:11:05,743: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:11:05] "GET / HTTP/1.1" 200 -
[2025-10-14 17:11:05,833: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:11:05] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:11:09,011: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 24, in predict
    output = model(image)
             ^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 246, in forward
    x = self.stn(x)
        ^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 228, in stn
    xs = xs.view(-1, 10 * 14 * 14)
         ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 1960]' is invalid for input of size 29160
[2025-10-14 17:11:09,015: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:11:09] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:13:01,358: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:13:01,358: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:13:02,224: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:13:02] "GET / HTTP/1.1" 200 -
[2025-10-14 17:13:02,484: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:13:02] "GET / HTTP/1.1" 200 -
[2025-10-14 17:13:02,567: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:13:02] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:13:05,827: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 24, in predict
    output = model(image)
             ^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 246, in forward
    x = self.stn(x)
        ^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 228, in stn
    xs = xs.view(-1, 10 * 14 * 14)
         ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 1960]' is invalid for input of size 29160
[2025-10-14 17:13:05,833: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:13:05] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:18:10,305: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:18:10,305: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:18:12,771: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:18:12] "GET / HTTP/1.1" 200 -
[2025-10-14 17:18:13,029: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:18:13] "GET / HTTP/1.1" 200 -
[2025-10-14 17:18:13,107: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:18:13] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:18:16,648: ERROR: app]: Exception on /predict [POST]
Traceback (most recent call last):
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\extension.py", line 176, in wrapped_function
    return cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\flask_cors\decorator.py", line 121, in wrapped_function
    resp = make_response(f(*args, **kwargs))
                         ^^^^^^^^^^^^^^^^^^
  File "F:\ProjectAI\FaceEmotionRecognitionSystem\app.py", line 35, in predict
    prediction, accuracy = clApp.classifier.predict()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\pipeline\prediction.py", line 24, in predict
    output = model(image)
             ^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\torch\nn\modules\module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 246, in forward
    x = self.stn(x)
        ^^^^^^^^^^^
  File "C:\Users\namnh\miniconda3\envs\FER_New\Lib\site-packages\FacialExpressionRecognition\models\emonext.py", line 228, in stn
    xs = xs.view(-1, 10 * 14 * 14)
         ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: shape '[-1, 1960]' is invalid for input of size 29160
[2025-10-14 17:18:16,648: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:18:16] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
[2025-10-14 17:22:38,880: INFO: _internal]: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8080
 * Running on http://192.168.1.243:8080
[2025-10-14 17:22:38,880: INFO: _internal]: [33mPress CTRL+C to quit[0m
[2025-10-14 17:22:43,568: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:22:43] "GET / HTTP/1.1" 200 -
[2025-10-14 17:22:43,820: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:22:43] "GET / HTTP/1.1" 200 -
[2025-10-14 17:22:43,903: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:22:43] "[33mGET /.well-known/appspecific/com.chrome.devtools.json HTTP/1.1[0m" 404 -
[2025-10-14 17:22:47,696: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:22:47] "POST /predict HTTP/1.1" 200 -
[2025-10-14 17:22:59,646: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:22:59] "POST /predict HTTP/1.1" 200 -
[2025-10-14 17:23:02,763: INFO: _internal]: 127.0.0.1 - - [14/Oct/2025 17:23:02] "POST /predict HTTP/1.1" 200 -
[2025-10-14 17:26:24,180: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-10-14 17:26:24,196: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 17:26:24,211: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 17:26:24,211: INFO: common]: Directory created at: artifacts
[2025-10-14 17:31:17,672: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-10-14 17:31:17,672: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 17:31:17,672: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 17:31:17,672: INFO: common]: Directory created at: artifacts
[2025-10-14 17:31:32,057: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-10-14 17:31:32,073: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 17:31:32,073: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 17:31:32,073: INFO: common]: Directory created at: artifacts
[2025-10-14 17:34:33,391: INFO: common]: JSON file saved at: scores.json
[2025-10-14 17:36:43,578: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-10-14 17:36:43,594: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 17:36:43,594: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 17:36:43,594: INFO: common]: Directory created at: artifacts
[2025-10-14 17:39:42,704: INFO: common]: JSON file saved at: scores.json
[2025-10-14 17:39:44,926: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-10-14 17:39:44,942: INFO: helpers]: Accessing as nhut-nam
[2025-10-14 17:39:45,700: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-10-14 17:39:46,431: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-10-14 17:39:46,431: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-10-14 17:39:46,431: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-10-14 17:57:42,488: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-10-14 17:57:42,488: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 17:57:42,488: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 17:57:42,488: INFO: common]: Directory created at: artifacts
[2025-10-14 18:00:36,300: INFO: common]: JSON file saved at: scores.json
[2025-10-14 18:00:37,858: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-10-14 18:00:37,858: INFO: helpers]: Accessing as nhut-nam
[2025-10-14 18:00:38,778: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-10-14 18:00:40,119: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-10-14 18:00:40,135: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-10-14 18:00:40,135: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-10-14 18:02:04,514: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-10-14 18:02:04,529: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 18:02:04,529: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 18:02:04,529: INFO: common]: Directory created at: artifacts
[2025-10-14 18:04:58,870: INFO: common]: JSON file saved at: scores.json
[2025-10-14 18:05:01,011: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-10-14 18:05:01,011: INFO: helpers]: Accessing as nhut-nam
[2025-10-14 18:05:03,061: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-10-14 18:05:03,752: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-10-14 18:05:03,752: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-10-14 18:05:03,752: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-10-14 20:42:50,222: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage started <<<<<<
[2025-10-14 20:42:50,222: INFO: common]: yaml file: config\config.yaml loaded successfully
[2025-10-14 20:42:50,226: INFO: common]: yaml file: params.yaml loaded successfully
[2025-10-14 20:42:50,226: INFO: common]: Directory created at: artifacts
[2025-10-14 20:45:49,286: INFO: common]: JSON file saved at: scores.json
[2025-10-14 20:45:51,498: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-10-14 20:45:51,514: INFO: helpers]: Accessing as nhut-nam
[2025-10-14 20:45:52,550: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/repos/nhut-nam/FaceEmotionRecognitionSystemTest "HTTP/1.1 200 OK"
[2025-10-14 20:45:53,273: INFO: _client]: HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[2025-10-14 20:45:53,277: INFO: helpers]: Initialized MLflow to track repo "nhut-nam/FaceEmotionRecognitionSystemTest"
[2025-10-14 20:45:53,279: INFO: helpers]: Repository nhut-nam/FaceEmotionRecognitionSystemTest initialized!
[2025-10-14 20:52:18,149: INFO: stage_04_model_evalution_with_mlflow]: >>>>>> stage Model Evaluation stage completed <<<<<<

x==========x
